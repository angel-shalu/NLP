{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJWwhpvyJlt9"
      },
      "source": [
        "# WEB- SCRAPING ON xml file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTai6M3nJgMi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FfeBLd6JhYS",
        "outputId": "801faafd-e663-47f6-89c3-fd600ed61159"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "0901c7918047d0e2\n",
            "\n",
            "Orphan Drug Approvals\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "WebMD, LLC\n",
            "\n",
            "\n",
            "\n",
            "index\n",
            "\n",
            "\n",
            "\n",
            "0901c79180555528\n",
            "\n",
            "\n",
            "News Alert\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "FDA Grants Orphan Drug Status to Gevokizumab\n",
            "\n",
            "The FDA has granted orphan drug designation to gevokizumab for the treatment of noninfectious intermediate uveitis, posterior uveitis, or panuveitis, or chronic noninfectious anterior uveitis.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Troy Brown\n",
            "\n",
            "Journalist\n",
            "\n",
            "Troy Brown is a freelance writer for Medscape.\n",
            "\n",
            "\n",
            "Disclosure\n",
            "Troy Brown has disclosed no relevant financial relationships.\n",
            "\n",
            "\n",
            "Title\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "29\n",
            "08\n",
            "2012\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "choroiditis,cyclitis,intermediate uveitis,orphan drugs,pars planitis,posterior uveitis\n",
            "\n",
            "\n",
            "\n",
            "29\n",
            "08\n",
            "2012\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "August 29, 2012 — The US Food and Drug Administration (FDA) has granted orphan drug status to gevokizumab (Xoma 052, Xoma Corp), a monoclonal antibody that binds strongly to interleukin 1β (IL-1β), for the treatment of noninfectious intermediate uveitis, posterior uveitis, or panuveitis, or chronic noninfectious anterior uveitis.\n",
            "The Orphan Drug Act of 1983 was passed to encourage companies to develop treatments for rare diseases (diseases that affect fewer than 200,000 people in the United States). Because the market is so small, such treatments can be unprofitable to develop. Companies that develop orphan drugs receive a 50% tax credit for the cost of conducting human clinical trials, 7-year marketing exclusivity, and other incentives.\n",
            "Behçet's disease is a rare multisystem disease that causes blood vessel inflammation throughout the body. Common symptoms are mouth sores, genital sores, and a type of panuveitis known as Behçet's uveitis, an inflammation of the uvea, retina, and vitreous humor that can lead to retinal detachment, vitreous hemorrhage, glaucoma, and blindness.\n",
            "\"A genetic association has been shown between Behçet's disease and the IL-1 gene cluster, and IL-1β has been implicated as a mediator in Behçet's disease pathogenesis,\" Christine Kay, MD, the director of Retinal Clinical Research and the director of the Electrophysiology Service in the Vitreoretinal Division of the Department of Ophthalmology at the University of Florida in Gainesville, told Medscape Medical News. Dr. Kay is a clinical correspondent for the American Academy of Ophthalmology.\n",
            "\"Gevokizumab regulates the activation of IL-1 receptors and can be intravenously or subcutaneously administered,\" Dr. Kay added.\n",
            "Patients with Behçet's uveitis have few treatment options. \"There are currently only 2 drugs FDA-approved for the treatment of chronic noninfectious intermediate, posterior, and panuveitis (Retisertand Ozurdex ), and both are extended-release corticosteroid ocular implants,\" Dr. Kay said.\n",
            "Results of a proof-of-concept phase 2 trial of intravenous gevokizumab in 7 patients with Behçet's uveitis were published in the April issue of the Annals of Rheumatic Diseases. In that trial patients were given a single infusion of gevokizumab (0.3 mg/kg), and all patients experienced complete reduction of intraocular inflammation in between 4 and 21 days (median, 14 days). There were no treatment-related adverse events.\n",
            "\"In clinical trials, so far, gevokizumab has been studied in nearly 500 patients. The studies have shown that gevokizumab is well-tolerated, and no drug-related adverse events have been reported,\" Fred Kurland, chief financial officer of Xoma, said in an email interview with Medscape Medical News.\n",
            "Although it appears that gevokizumab \"may offer a viable treatment option in Behçet's disease, it remains to be seen if an IL-1 antibody will have an effect in other forms of noninfectious uveitis. A phase 3 clinical trial to evaluate the efficacy ofin the treatment of noninfectious uveitis is in the recruitment process,\" Dr. Kay said.\n",
            "\"Gevokizumab does offer the possibility of a pathophysiology-driven targeted therapy for IL-1 related uveitis, and if proven safe and effective in a phase 3 trial, this could provide a valuable option in the treatment of noninfectious intermediate uveitis, posterior uveitis, and panuveitis. Even if this drug is only shown to be effective in Behçet's disease, this could provide a useful and targeted treatment for an extremely aggressive condition, perhaps limiting broader and more toxic immunosuppression,\" Dr. Kay said.\n",
            "\n",
            "Other Potential Indications\n",
            "\n",
            "\"As an IL-1β inhibitor, gevokizumab has potential in a very large number of indications that are driven by inflammation, such as noninfectious uveitis.... e are also engaged in 2 proof-of-concept phase 2 trials using gevokizumab in patients with moderate to severe acne vulgaris and in erosive osteoarthritis of the hand, and we will initiate a third proof-of-concept trial in another indication later this year,\" Kurland explained.\n",
            "\"With respect to themarket specifically, we estimate that there are approximately 150,000 patients in the ,\" Kurland added, noting they are not discussing the drug's pricing yet.\n",
            "\n",
            "Dr. Kay has disclosed no relevant financial relationships.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Acknowledgements\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# XML scrapping for xml sheet \n",
        "\n",
        "import os\n",
        "os.chdir(r\"C:\\Users\\shali\\Desktop\\DS_Road_Map\\9. NLP\\NLP WEB SCRAPING\\xml_single articles\")\n",
        "\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "tree = ET.parse(\"769952.xml\") \n",
        "root = tree.getroot()\n",
        "\n",
        "root=ET.tostring(root, encoding='utf8').decode('utf8')\n",
        "\n",
        "root\n",
        "\n",
        "import re, string, unicodedata\n",
        "import nltk\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
        "\n",
        "def strip_html(text):\n",
        "    soup = BeautifulSoup(text, \"xml\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def remove_between_square_brackets(text):\n",
        "    return re.sub(r'\\[[^]]*\\]', '', text)\n",
        "\n",
        "def denoise_text(text):\n",
        "    text = strip_html(text)\n",
        "    text = remove_between_square_brackets(text)\n",
        "    text=re.sub('  ','',text)\n",
        "    return text\n",
        "\n",
        "sample = denoise_text(root)\n",
        "print(sample)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nf-o4a9dRJqd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c12AaqYrS_AC",
        "outputId": "cf32b289-5f6e-401a-e016-bfb12b98a809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"XML_Data_Extractor_Visualizer.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/1YrQh3p3_5J3v0_3p5_6_7v8w9x0y1z2\n",
        "\"\"\"\n",
        "\n",
        "# !pip install gradio\n",
        "# !pip install xmltodict\n",
        "# !pip install beautifulsoup4\n",
        "\n",
        "import gradio as gr\n",
        "import xml.etree.ElementTree as ET\n",
        "import xmltodict\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "def parse_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Parse XML content from either file upload or text input\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if input_type == \"file\":\n",
        "            # Ensure the file object is read correctly\n",
        "            if hasattr(xml_content, 'name'):\n",
        "                with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "                    xml_string = f.read()\n",
        "            else:\n",
        "                 return None, None, None, \"Invalid file object provided.\"\n",
        "        else:\n",
        "            xml_string = xml_content\n",
        "\n",
        "        # Parse with ElementTree\n",
        "        root = ET.fromstring(xml_string)\n",
        "\n",
        "        # Convert to dict for easier processing\n",
        "        xml_dict = xmltodict.parse(xml_string)\n",
        "\n",
        "        return root, xml_dict, xml_string, None\n",
        "    except Exception as e:\n",
        "        return None, None, None, str(e)\n",
        "\n",
        "def extract_xml_structure(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract and display the structure of the XML document\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Create a structure visualization\n",
        "    structure = []\n",
        "\n",
        "    def traverse(node, depth=0):\n",
        "        structure.append(\"  \" * depth + f\"<{node.tag}>\")\n",
        "        for child in node:\n",
        "            traverse(child, depth + 1)\n",
        "        if not list(node):  # If no children, show text content if exists\n",
        "            if node.text and node.text.strip():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"Text: {node.text.strip()}\")\n",
        "\n",
        "    traverse(root)\n",
        "    return \"\\n\".join(structure)\n",
        "\n",
        "def extract_xml_data(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract data from XML and present in a readable format\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\", \"\"\n",
        "\n",
        "    # Convert to pretty JSON for display\n",
        "    json_data = json.dumps(xml_dict, indent=2)\n",
        "\n",
        "    # Create a simplified table view for common XML structures\n",
        "    tables = []\n",
        "\n",
        "    # Try to find repeating elements that might form a table\n",
        "    def find_tables(node, path=\"\"):\n",
        "        if len(node) > 0:\n",
        "            # Check if all children have the same structure\n",
        "            child_tags = [child.tag for child in node]\n",
        "            if len(set(child_tags)) == 1 and len(child_tags) > 1:\n",
        "                # This might be a table-like structure\n",
        "                columns = set()\n",
        "                for child in node:\n",
        "                    for grandchild in child:\n",
        "                        columns.add(grandchild.tag)\n",
        "\n",
        "                if columns:\n",
        "                    # Create a table\n",
        "                    table_data = []\n",
        "                    for child in node:\n",
        "                        row = {}\n",
        "                        for grandchild in child:\n",
        "                            row[grandchild.tag] = grandchild.text if grandchild.text else \"\"\n",
        "                        table_data.append(row)\n",
        "\n",
        "                    if table_data:\n",
        "                        df = pd.DataFrame(table_data)\n",
        "                        tables.append((f\"Table from {path}/{node.tag}\", df))\n",
        "\n",
        "            # Recursively process children\n",
        "            for child in node:\n",
        "                find_tables(child, f\"{path}/{node.tag}\")\n",
        "\n",
        "    find_tables(root)\n",
        "\n",
        "    # Format tables for display\n",
        "    tables_html = \"<h2>Extracted Tables</h2>\"\n",
        "    if tables:\n",
        "        for name, df in tables:\n",
        "            tables_html += f\"<h3>{name}</h3>\"\n",
        "            tables_html += df.to_html()\n",
        "    else:\n",
        "        tables_html += \"<p>No table-like structures detected</p>\"\n",
        "\n",
        "    return json_data, tables_html\n",
        "\n",
        "def visualize_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Create visualizations from XML data\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Count elements by tag\n",
        "    tag_count = defaultdict(int)\n",
        "\n",
        "    def count_tags(node):\n",
        "        tag_count[node.tag] += 1\n",
        "        for child in node:\n",
        "            count_tags(child)\n",
        "\n",
        "    count_tags(root)\n",
        "\n",
        "    # Create a bar chart of tag frequencies\n",
        "    if tag_count:\n",
        "        fig = px.bar(x=list(tag_count.keys()), y=list(tag_count.values()),\n",
        "                     labels={'x': 'XML Tags', 'y': 'Count'},\n",
        "                     title='Frequency of XML Tags')\n",
        "        return fig\n",
        "    else:\n",
        "        return \"No data available for visualization\"\n",
        "\n",
        "def clean_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Clean and format XML content\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Pretty print the XML\n",
        "    soup = BeautifulSoup(xml_string, 'xml')\n",
        "    pretty_xml = soup.prettify()\n",
        "\n",
        "    return pretty_xml\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"XML Data Extractor and Visualizer\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # XML Data Extractor and Visualizer\n",
        "    Upload an XML file or paste XML content to explore its structure, extract data, and create visualizations.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tab(\"XML Input\"):\n",
        "        input_type = gr.Radio([\"file\", \"text\"], value=\"file\", label=\"Input Type\")\n",
        "        xml_input = gr.File(label=\"Upload XML File\", file_types=[\".xml\"])\n",
        "        xml_text = gr.Textbox(label=\"Or Paste XML Content\", lines=10, visible=False)\n",
        "\n",
        "        def toggle_input(choice):\n",
        "            if choice == \"file\":\n",
        "                return gr.File(visible=True), gr.Textbox(visible=False)\n",
        "            else:\n",
        "                return gr.File(visible=False), gr.Textbox(visible=True)\n",
        "\n",
        "        input_type.change(toggle_input, input_type, [xml_input, xml_text])\n",
        "\n",
        "    with gr.Tab(\"XML Structure\"):\n",
        "        structure_btn = gr.Button(\"Extract Structure\")\n",
        "        structure_output = gr.Textbox(label=\"XML Structure\", lines=15)\n",
        "\n",
        "    with gr.Tab(\"Data Extraction\"):\n",
        "        extract_btn = gr.Button(\"Extract Data\")\n",
        "        with gr.Row():\n",
        "            json_output = gr.Textbox(label=\"JSON Representation\", lines=15)\n",
        "            table_output = gr.HTML(label=\"Tabular Data\")\n",
        "\n",
        "    with gr.Tab(\"Visualization\"):\n",
        "        viz_btn = gr.Button(\"Create Visualization\")\n",
        "        viz_output = gr.Plot(label=\"Tag Frequency Visualization\")\n",
        "\n",
        "    with gr.Tab(\"XML Cleaner\"):\n",
        "        clean_btn = gr.Button(\"Clean and Format XML\")\n",
        "        clean_output = gr.Code(label=\"Formatted XML\", lines=15)\n",
        "\n",
        "    # Set up event handlers\n",
        "    structure_btn.click(\n",
        "        extract_xml_structure,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=structure_output\n",
        "    )\n",
        "\n",
        "    extract_btn.click(\n",
        "        extract_xml_data,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=[json_output, table_output]\n",
        "    )\n",
        "\n",
        "    viz_btn.click(\n",
        "        visualize_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=viz_output\n",
        "    )\n",
        "\n",
        "    clean_btn.click(\n",
        "        clean_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=clean_output\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0_E8TGES-9q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CYcm_GWzS-4x",
        "outputId": "46246e71-61cd-4a71-e15c-a82f84609976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (0.14.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://56bcbbe02904c0a8c1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://56bcbbe02904c0a8c1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://56bcbbe02904c0a8c1.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"XML_Data_Extractor_Visualizer.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/1YrQh3p3_5J3v0_3p5_6_7v8w9x0y1z2\n",
        "\"\"\"\n",
        "\n",
        "!pip install gradio\n",
        "!pip install xmltodict\n",
        "!pip install beautifulsoup4\n",
        "!pip install plotly\n",
        "\n",
        "import gradio as gr\n",
        "import xml.etree.ElementTree as ET\n",
        "import xmltodict\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def parse_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Parse XML content from either file upload or text input\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if input_type == \"file\":\n",
        "            if xml_content is None:\n",
        "                return None, None, None, \"No file uploaded\"\n",
        "            with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "                xml_string = f.read()\n",
        "        else:\n",
        "            xml_string = xml_content\n",
        "            if not xml_string.strip():\n",
        "                return None, None, None, \"No XML content provided\"\n",
        "\n",
        "        # Parse with ElementTree\n",
        "        root = ET.fromstring(xml_string)\n",
        "\n",
        "        # Convert to dict for easier processing\n",
        "        xml_dict = xmltodict.parse(xml_string)\n",
        "\n",
        "        return root, xml_dict, xml_string, None\n",
        "    except Exception as e:\n",
        "        return None, None, None, str(e)\n",
        "\n",
        "def extract_xml_structure(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract and display the structure of the XML document\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Create a structure visualization\n",
        "    structure = []\n",
        "\n",
        "    def traverse(node, depth=0):\n",
        "        structure.append(\"  \" * depth + f\"<{node.tag}>\")\n",
        "        # Add attributes if any\n",
        "        if node.attrib:\n",
        "            for attr, value in node.attrib.items():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"@{attr}: {value}\")\n",
        "        for child in node:\n",
        "            traverse(child, depth + 1)\n",
        "        if not list(node):  # If no children, show text content if exists\n",
        "            if node.text and node.text.strip():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"Text: {node.text.strip()}\")\n",
        "        structure.append(\"  \" * depth + f\"</{node.tag}>\")\n",
        "\n",
        "    traverse(root)\n",
        "    return \"\\n\".join(structure)\n",
        "\n",
        "def extract_xml_data(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract data from XML and present in a readable format\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\", \"<p>Error parsing XML</p>\"\n",
        "\n",
        "    # Convert to pretty JSON for display\n",
        "    try:\n",
        "        json_data = json.dumps(xml_dict, indent=2)\n",
        "    except:\n",
        "        json_data = \"Could not convert to JSON format\"\n",
        "\n",
        "    # Extract all data from XML in a structured way\n",
        "    extracted_data = []\n",
        "\n",
        "    def extract_elements(node, path=\"\"):\n",
        "        current_path = f\"{path}/{node.tag}\" if path else node.tag\n",
        "\n",
        "        # Extract element data\n",
        "        element_data = {\n",
        "            \"path\": current_path,\n",
        "            \"tag\": node.tag,\n",
        "            \"attributes\": dict(node.attrib),\n",
        "            \"text\": node.text.strip() if node.text and node.text.strip() else None,\n",
        "            \"children\": len(list(node))\n",
        "        }\n",
        "        extracted_data.append(element_data)\n",
        "\n",
        "        # Process children\n",
        "        for child in node:\n",
        "            extract_elements(child, current_path)\n",
        "\n",
        "    extract_elements(root)\n",
        "\n",
        "    # Create a DataFrame for display\n",
        "    df = pd.DataFrame(extracted_data)\n",
        "\n",
        "    # Create HTML table\n",
        "    if not df.empty:\n",
        "        table_html = df.to_html(classes='table table-striped', index=False, escape=False)\n",
        "    else:\n",
        "        table_html = \"<p>No data could be extracted from the XML</p>\"\n",
        "\n",
        "    return json_data, table_html\n",
        "\n",
        "def extract_xml_data_as_table(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract data from XML and present in a tabular format\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\", \"<p>Error parsing XML</p>\"\n",
        "\n",
        "    # Find repeating elements that could form a table\n",
        "    tables = []\n",
        "\n",
        "    def find_table_data(node, path=\"\"):\n",
        "        # If this node has children and all children have the same tag, it might be a table\n",
        "        children = list(node)\n",
        "        if children:\n",
        "            child_tags = [child.tag for child in children]\n",
        "            if len(set(child_tags)) == 1 and len(children) > 1:\n",
        "                # This looks like a table row structure\n",
        "                table_rows = []\n",
        "                for child in children:\n",
        "                    row = {\"_row_type\": child.tag}\n",
        "                    for grandchild in child:\n",
        "                        row[grandchild.tag] = grandchild.text.strip() if grandchild.text and grandchild.text.strip() else \"\"\n",
        "                    table_rows.append(row)\n",
        "\n",
        "                if table_rows:\n",
        "                    tables.append({\n",
        "                        \"name\": f\"{path}/{node.tag}\",\n",
        "                        \"data\": table_rows\n",
        "                    })\n",
        "\n",
        "        # Recursively process children\n",
        "        for child in children:\n",
        "            find_table_data(child, f\"{path}/{node.tag}\")\n",
        "\n",
        "    find_table_data(root)\n",
        "\n",
        "    # Generate HTML for tables\n",
        "    tables_html = \"<h2>Extracted Data Tables</h2>\"\n",
        "\n",
        "    if tables:\n",
        "        for i, table in enumerate(tables):\n",
        "            df = pd.DataFrame(table[\"data\"])\n",
        "            tables_html += f\"<h3>Table {i+1}: {table['name']}</h3>\"\n",
        "            tables_html += df.to_html(classes='table table-striped', index=False)\n",
        "    else:\n",
        "        tables_html += \"<p>No table-like structures found. Showing all elements:</p>\"\n",
        "\n",
        "        # Fallback: show all elements in a table\n",
        "        all_data = []\n",
        "\n",
        "        def extract_all_elements(node, path=\"\"):\n",
        "            current_path = f\"{path}/{node.tag}\" if path else node.tag\n",
        "            element_data = {\n",
        "                \"Path\": current_path,\n",
        "                \"Tag\": node.tag,\n",
        "                \"Attributes\": str(node.attrib),\n",
        "                \"Text\": node.text.strip() if node.text and node.text.strip() else \"\",\n",
        "                \"Children\": len(list(node))\n",
        "            }\n",
        "            all_data.append(element_data)\n",
        "\n",
        "            for child in node:\n",
        "                extract_all_elements(child, current_path)\n",
        "\n",
        "        extract_all_elements(root)\n",
        "        df = pd.DataFrame(all_data)\n",
        "        tables_html += df.to_html(classes='table table-striped', index=False)\n",
        "\n",
        "    return tables_html\n",
        "\n",
        "def visualize_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Create visualizations from XML data\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Count elements by tag\n",
        "    tag_count = defaultdict(int)\n",
        "\n",
        "    def count_tags(node):\n",
        "        tag_count[node.tag] += 1\n",
        "        for child in node:\n",
        "            count_tags(child)\n",
        "\n",
        "    count_tags(root)\n",
        "\n",
        "    # Create a bar chart of tag frequencies\n",
        "    if tag_count:\n",
        "        fig = px.bar(x=list(tag_count.keys()), y=list(tag_count.values()),\n",
        "                     labels={'x': 'XML Tags', 'y': 'Count'},\n",
        "                     title='Frequency of XML Tags')\n",
        "        return fig\n",
        "    else:\n",
        "        return \"No data available for visualization\"\n",
        "\n",
        "def clean_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Clean and format XML content\n",
        "    \"\"\"\n",
        "    if input_type == \"file\":\n",
        "        if xml_content is None:\n",
        "            return \"No file uploaded\"\n",
        "        with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "            xml_string = f.read()\n",
        "    else:\n",
        "        xml_string = xml_content\n",
        "        if not xml_string.strip():\n",
        "            return \"No XML content provided\"\n",
        "\n",
        "    # Pretty print the XML\n",
        "    try:\n",
        "        soup = BeautifulSoup(xml_string, 'xml')\n",
        "        pretty_xml = soup.prettify()\n",
        "        return pretty_xml\n",
        "    except Exception as e:\n",
        "        return f\"Error formatting XML: {str(e)}\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"XML Data Extractor and Visualizer\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🔍 XML Data Extractor and Visualizer\n",
        "    Upload an XML file or paste XML content to explore its structure, extract data, and create visualizations.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_type = gr.Radio([\"file\", \"text\"], value=\"file\", label=\"Input Type\")\n",
        "            xml_input = gr.File(label=\"Upload XML File\", file_types=[\".xml\"])\n",
        "            xml_text = gr.Textbox(label=\"Or Paste XML Content\", lines=10, visible=False)\n",
        "\n",
        "            def toggle_input(choice):\n",
        "                if choice == \"file\":\n",
        "                    return gr.File(visible=True), gr.Textbox(visible=False)\n",
        "                else:\n",
        "                    return gr.File(visible=False), gr.Textbox(visible=True)\n",
        "\n",
        "            input_type.change(toggle_input, input_type, [xml_input, xml_text])\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### 📊 What you can do:\n",
        "            - **View Structure**: See the hierarchical structure of your XML\n",
        "            - **Extract Data**: Convert XML to JSON and detect table structures\n",
        "            - **Visualize**: Create charts showing tag frequencies\n",
        "            - **Clean XML**: Format and prettify your XML code\n",
        "\n",
        "            ### 🚀 Try with this sample XML:\n",
        "            ```xml\n",
        "            <catalog>\n",
        "              <book id=\"101\">\n",
        "                <author>John Doe</author>\n",
        "                <title>XML Guide</title>\n",
        "                <price>29.99</price>\n",
        "              </book>\n",
        "              <book id=\"102\">\n",
        "                <author>Jane Smith</author>\n",
        "                <title>Python Programming</title>\n",
        "                <price>39.99</price>\n",
        "              </book>\n",
        "            </catalog>\n",
        "            ```\n",
        "            \"\"\")\n",
        "\n",
        "    with gr.Tab(\"📁 XML Structure\"):\n",
        "        gr.Markdown(\"### XML Document Structure\")\n",
        "        structure_btn = gr.Button(\"Extract Structure\", variant=\"primary\")\n",
        "        structure_output = gr.Code(label=\"XML Structure\", language=\"markdown\", lines=15)\n",
        "\n",
        "    with gr.Tab(\"📊 Data Extraction\"):\n",
        "        gr.Markdown(\"### Extracted Data from XML\")\n",
        "        extract_btn = gr.Button(\"Extract Data\", variant=\"primary\")\n",
        "        with gr.Row():\n",
        "            json_output = gr.Code(label=\"JSON Representation\", language=\"json\", lines=15)\n",
        "            table_output = gr.HTML(label=\"Tabular Data\")\n",
        "\n",
        "    with gr.Tab(\"📈 Visualization\"):\n",
        "        gr.Markdown(\"### XML Data Visualization\")\n",
        "        viz_btn = gr.Button(\"Create Visualization\", variant=\"primary\")\n",
        "        viz_output = gr.Plot(label=\"Tag Frequency Visualization\")\n",
        "\n",
        "    with gr.Tab(\"✨ XML Cleaner\"):\n",
        "        gr.Markdown(\"### Clean and Format XML\")\n",
        "        clean_btn = gr.Button(\"Clean and Format XML\", variant=\"primary\")\n",
        "        clean_output = gr.Code(label=\"Formatted XML\", language=\"html\", lines=15)\n",
        "\n",
        "    # Set up event handlers\n",
        "    structure_btn.click(\n",
        "        extract_xml_structure,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=structure_output\n",
        "    )\n",
        "\n",
        "    extract_btn.click(\n",
        "        extract_xml_data,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=[json_output, table_output]\n",
        "    )\n",
        "\n",
        "    viz_btn.click(\n",
        "        visualize_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=viz_output\n",
        "    )\n",
        "\n",
        "    clean_btn.click(\n",
        "        clean_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=clean_output\n",
        "    )\n",
        "\n",
        "# For Google Colab, we need to handle the launch differently\n",
        "def launch_in_colab():\n",
        "    # Create a public link\n",
        "    demo.launch(share=True, debug=True)\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    # This will work in both Colab and local environments\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        IN_COLAB = False\n",
        "\n",
        "    if IN_COLAB:\n",
        "        launch_in_colab()\n",
        "    else:\n",
        "        demo.launch(debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nSeWPsyS-2P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "96Ot85flXIqX",
        "outputId": "f0b0f738-154d-4f5b-98fe-3fbc27603d09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.12/dist-packages (5.42.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.12/dist-packages (from gradio) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (1.11.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.33.5 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.34.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (3.11.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from gradio) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (11.3.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.12/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.12.9)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (4.14.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.12/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (2025.3.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.12/dist-packages (from gradio-client==1.11.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (3.19.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.33.5->gradio) (1.1.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<1.0,>=0.33.5->gradio) (2.5.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.12/dist-packages (0.14.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.14.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from plotly) (25.0)\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://7b180ba37e00500d9a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://7b180ba37e00500d9a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://7b180ba37e00500d9a.gradio.live\n"
          ]
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"XML_Data_Extractor_Visualizer.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at:\n",
        "    https://colab.research.google.com/drive/1YrQh3p3_5J3v0_3p5_6_7v8w9x0y1z2\n",
        "\"\"\"\n",
        "\n",
        "!pip install gradio\n",
        "!pip install xmltodict\n",
        "!pip install beautifulsoup4\n",
        "!pip install plotly\n",
        "\n",
        "import gradio as gr\n",
        "import xml.etree.ElementTree as ET\n",
        "import xmltodict\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "def parse_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Parse XML content from either file upload or text input\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if input_type == \"file\":\n",
        "            if xml_content is None:\n",
        "                return None, None, None, \"No file uploaded\"\n",
        "            with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "                xml_string = f.read()\n",
        "        else:\n",
        "            xml_string = xml_content\n",
        "            if not xml_string.strip():\n",
        "                return None, None, None, \"No XML content provided\"\n",
        "\n",
        "        # Parse with ElementTree\n",
        "        root = ET.fromstring(xml_string)\n",
        "\n",
        "        # Convert to dict for easier processing\n",
        "        xml_dict = xmltodict.parse(xml_string)\n",
        "\n",
        "        return root, xml_dict, xml_string, None\n",
        "    except Exception as e:\n",
        "        return None, None, None, str(e)\n",
        "\n",
        "def extract_xml_structure(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract and display the structure of the XML document\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Create a structure visualization\n",
        "    structure = []\n",
        "\n",
        "    def traverse(node, depth=0):\n",
        "        structure.append(\"  \" * depth + f\"<{node.tag}>\")\n",
        "        # Add attributes if any\n",
        "        if node.attrib:\n",
        "            for attr, value in node.attrib.items():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"@{attr}: {value}\")\n",
        "        for child in node:\n",
        "            traverse(child, depth + 1)\n",
        "        if not list(node):  # If no children, show text content if exists\n",
        "            if node.text and node.text.strip():\n",
        "                structure.append(\"  \" * (depth + 1) + f\"Text: {node.text.strip()}\")\n",
        "        structure.append(\"  \" * depth + f\"</{node.tag}>\")\n",
        "\n",
        "    traverse(root)\n",
        "    return \"\\n\".join(structure)\n",
        "\n",
        "def extract_xml_data(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Extract data from XML and present in a readable format\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\", \"<p>Error parsing XML</p>\"\n",
        "\n",
        "    # Convert to pretty JSON for display\n",
        "    try:\n",
        "        json_data = json.dumps(xml_dict, indent=2)\n",
        "    except:\n",
        "        json_data = \"Could not convert to JSON format\"\n",
        "\n",
        "    # Extract all data from XML in a structured way\n",
        "    extracted_data = []\n",
        "\n",
        "    def extract_elements(node, path=\"\"):\n",
        "        current_path = f\"{path}/{node.tag}\" if path else node.tag\n",
        "\n",
        "        # Extract element data\n",
        "        element_data = {\n",
        "            \"path\": current_path,\n",
        "            \"tag\": node.tag,\n",
        "            \"attributes\": dict(node.attrib),\n",
        "            \"text\": node.text.strip() if node.text and node.text.strip() else None,\n",
        "            \"children\": len(list(node))\n",
        "        }\n",
        "        extracted_data.append(element_data)\n",
        "\n",
        "        # Process children\n",
        "        for child in node:\n",
        "            extract_elements(child, current_path)\n",
        "\n",
        "    extract_elements(root)\n",
        "\n",
        "    # Create a DataFrame for display\n",
        "    df = pd.DataFrame(extracted_data)\n",
        "\n",
        "    # Create HTML table\n",
        "    if not df.empty:\n",
        "        table_html = df.to_html(classes='table table-striped', index=False, escape=False)\n",
        "    else:\n",
        "        table_html = \"<p>No data could be extracted from the XML</p>\"\n",
        "\n",
        "    return json_data, table_html\n",
        "\n",
        "def generate_insights(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Generate meaningful insights about the XML structure and content\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"<p style='color: red;'>Error parsing XML: {error}</p>\"\n",
        "\n",
        "    insights_html = \"<div style='font-family: Arial, sans-serif;'>\"\n",
        "    insights_html += \"<h2 style='color: #2E86AB;'>📊 XML Insights & Analysis</h2>\"\n",
        "\n",
        "    # Basic statistics\n",
        "    total_elements = 0\n",
        "    elements_with_attributes = 0\n",
        "    elements_with_text = 0\n",
        "    max_depth = 0\n",
        "    tag_counts = defaultdict(int)\n",
        "    attribute_counts = defaultdict(int)\n",
        "\n",
        "    def analyze_node(node, depth=0):\n",
        "        nonlocal total_elements, elements_with_attributes, elements_with_text, max_depth\n",
        "        total_elements += 1\n",
        "        tag_counts[node.tag] += 1\n",
        "        max_depth = max(max_depth, depth)\n",
        "\n",
        "        if node.attrib:\n",
        "            elements_with_attributes += 1\n",
        "            for attr in node.attrib:\n",
        "                attribute_counts[attr] += 1\n",
        "\n",
        "        if node.text and node.text.strip():\n",
        "            elements_with_text += 1\n",
        "\n",
        "        for child in node:\n",
        "            analyze_node(child, depth + 1)\n",
        "\n",
        "    analyze_node(root)\n",
        "\n",
        "    # Generate insights\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>📈 Basic Statistics</h3>\"\n",
        "    insights_html += f\"<ul>\"\n",
        "    insights_html += f\"<li>Total Elements: <b>{total_elements}</b></li>\"\n",
        "    insights_html += f\"<li>Maximum Depth: <b>{max_depth}</b> levels</li>\"\n",
        "    insights_html += f\"<li>Elements with Attributes: <b>{elements_with_attributes}</b> ({elements_with_attributes/total_elements*100:.1f}%)</li>\"\n",
        "    insights_html += f\"<li>Elements with Text Content: <b>{elements_with_text}</b> ({elements_with_text/total_elements*100:.1f}%)</li>\"\n",
        "    insights_html += f\"</ul>\"\n",
        "\n",
        "    # Tag frequency analysis\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>🏷️ Tag Frequency</h3>\"\n",
        "    if tag_counts:\n",
        "        insights_html += f\"<p>Unique Tags: <b>{len(tag_counts)}</b></p>\"\n",
        "        insights_html += \"<table style='width: 100%; border-collapse: collapse;'><tr><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Tag</th><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Count</th><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Percentage</th></tr>\"\n",
        "\n",
        "        for tag, count in sorted(tag_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "            percentage = (count / total_elements) * 100\n",
        "            insights_html += f\"<tr><td style='border: 1px solid #ddd; padding: 8px;'>{tag}</td><td style='border: 1px solid #ddd; padding: 8px;'>{count}</td><td style='border: 1px solid #ddd; padding: 8px;'>{percentage:.1f}%</td></tr>\"\n",
        "\n",
        "        insights_html += \"</table>\"\n",
        "\n",
        "        if len(tag_counts) > 10:\n",
        "            insights_html += f\"<p>... and {len(tag_counts) - 10} more tags</p>\"\n",
        "\n",
        "    # Attribute analysis\n",
        "    if attribute_counts:\n",
        "        insights_html += f\"<h3 style='color: #A23B72;'>🔗 Attributes</h3>\"\n",
        "        insights_html += f\"<p>Unique Attributes: <b>{len(attribute_counts)}</b></p>\"\n",
        "        insights_html += \"<table style='width: 100%; border-collapse: collapse;'><tr><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Attribute</th><th style='border: 1px solid #ddd; padding: 8px; background-color: #f2f2f2;'>Count</th></tr>\"\n",
        "\n",
        "        for attr, count in sorted(attribute_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "            insights_html += f\"<tr><td style='border: 1px solid #ddd; padding: 8px;'>{attr}</td><td style='border: 1px solid #ddd; padding: 8px;'>{count}</td></tr>\"\n",
        "\n",
        "        insights_html += \"</table>\"\n",
        "\n",
        "        if len(attribute_counts) > 10:\n",
        "            insights_html += f\"<p>... and {len(attribute_counts) - 10} more attributes</p>\"\n",
        "\n",
        "    # Structural insights\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>🏗️ Structural Insights</h3>\"\n",
        "\n",
        "    # Check for potential data tables\n",
        "    potential_tables = []\n",
        "\n",
        "    def find_potential_tables(node, path=\"\"):\n",
        "        children = list(node)\n",
        "        if children:\n",
        "            child_tags = [child.tag for child in children]\n",
        "            if len(set(child_tags)) == 1 and len(children) > 1:\n",
        "                # This looks like a table structure\n",
        "                sample_child = children[0]\n",
        "                grandchild_count = len(list(sample_child))\n",
        "\n",
        "                potential_tables.append({\n",
        "                    \"path\": f\"{path}/{node.tag}\",\n",
        "                    \"row_tag\": child_tags[0],\n",
        "                    \"row_count\": len(children),\n",
        "                    \"column_count\": grandchild_count\n",
        "                })\n",
        "\n",
        "        for child in children:\n",
        "            find_potential_tables(child, f\"{path}/{node.tag}\")\n",
        "\n",
        "    find_potential_tables(root)\n",
        "\n",
        "    if potential_tables:\n",
        "        insights_html += f\"<p>Found <b>{len(potential_tables)}</b> potential data table(s):</p>\"\n",
        "        insights_html += \"<ul>\"\n",
        "        for table in potential_tables:\n",
        "            insights_html += f\"<li>Location: <code>{table['path']}</code> - {table['row_count']} rows × {table['column_count']} columns</li>\"\n",
        "        insights_html += \"</ul>\"\n",
        "    else:\n",
        "        insights_html += \"<p>No obvious table structures detected. This might be a document-oriented XML.</p>\"\n",
        "\n",
        "    # Data quality insights\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>✅ Data Quality Assessment</h3>\"\n",
        "\n",
        "    empty_elements = total_elements - elements_with_text\n",
        "    empty_percentage = (empty_elements / total_elements) * 100\n",
        "\n",
        "    if empty_percentage > 50:\n",
        "        insights_html += f\"<p style='color: #E56B70;'>⚠️ High percentage of empty elements ({empty_percentage:.1f}%). Consider if this is expected for your data model.</p>\"\n",
        "    else:\n",
        "        insights_html += f\"<p>Empty elements: {empty_percentage:.1f}% - This is within normal range.</p>\"\n",
        "\n",
        "    if elements_with_attributes == 0:\n",
        "        insights_html += f\"<p>No attributes found in the XML. This is a simple data structure.</p>\"\n",
        "\n",
        "    # Recommendations\n",
        "    insights_html += f\"<h3 style='color: #A23B72;'>💡 Recommendations</h3>\"\n",
        "    insights_html += \"<ul>\"\n",
        "\n",
        "    if max_depth > 5:\n",
        "        insights_html += \"<li>Deeply nested structure detected. Consider simplifying the hierarchy for better performance.</li>\"\n",
        "\n",
        "    if len(tag_counts) > 20:\n",
        "        insights_html += \"<li>Many different tags detected. This might be a complex data model.</li>\"\n",
        "\n",
        "    if potential_tables:\n",
        "        insights_html += \"<li>Table-like structures detected. You might want to convert these to CSV or database tables.</li>\"\n",
        "\n",
        "    insights_html += \"<li>For better visualization, consider using the 'Data Extraction' tab to view the data in tabular format.</li>\"\n",
        "    insights_html += \"</ul>\"\n",
        "\n",
        "    insights_html += \"</div>\"\n",
        "\n",
        "    return insights_html\n",
        "\n",
        "def visualize_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Create visualizations from XML data\n",
        "    \"\"\"\n",
        "    root, xml_dict, xml_string, error = parse_xml(xml_content, input_type)\n",
        "\n",
        "    if error:\n",
        "        return f\"Error parsing XML: {error}\"\n",
        "\n",
        "    # Count elements by tag\n",
        "    tag_count = defaultdict(int)\n",
        "\n",
        "    def count_tags(node):\n",
        "        tag_count[node.tag] += 1\n",
        "        for child in node:\n",
        "            count_tags(child)\n",
        "\n",
        "    count_tags(root)\n",
        "\n",
        "    # Create a bar chart of tag frequencies\n",
        "    if tag_count:\n",
        "        fig = px.bar(x=list(tag_count.keys()), y=list(tag_count.values()),\n",
        "                     labels={'x': 'XML Tags', 'y': 'Count'},\n",
        "                     title='Frequency of XML Tags')\n",
        "        return fig\n",
        "    else:\n",
        "        return \"No data available for visualization\"\n",
        "\n",
        "def clean_xml(xml_content, input_type):\n",
        "    \"\"\"\n",
        "    Clean and format XML content\n",
        "    \"\"\"\n",
        "    if input_type == \"file\":\n",
        "        if xml_content is None:\n",
        "            return \"No file uploaded\"\n",
        "        with open(xml_content.name, 'r', encoding='utf-8') as f:\n",
        "            xml_string = f.read()\n",
        "    else:\n",
        "        xml_string = xml_content\n",
        "        if not xml_string.strip():\n",
        "            return \"No XML content provided\"\n",
        "\n",
        "    # Pretty print the XML\n",
        "    try:\n",
        "        soup = BeautifulSoup(xml_string, 'xml')\n",
        "        pretty_xml = soup.prettify()\n",
        "        return pretty_xml\n",
        "    except Exception as e:\n",
        "        return f\"Error formatting XML: {str(e)}\"\n",
        "\n",
        "# Create the Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"XML Data Extractor and Visualizer\") as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # 🔍 XML Data Extractor and Visualizer\n",
        "    Upload an XML file or paste XML content to explore its structure, extract data, and create visualizations.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            input_type = gr.Radio([\"file\", \"text\"], value=\"file\", label=\"Input Type\")\n",
        "            xml_input = gr.File(label=\"Upload XML File\", file_types=[\".xml\"])\n",
        "            xml_text = gr.Textbox(label=\"Or Paste XML Content\", lines=10, visible=False)\n",
        "\n",
        "            def toggle_input(choice):\n",
        "                if choice == \"file\":\n",
        "                    return gr.File(visible=True), gr.Textbox(visible=False)\n",
        "                else:\n",
        "                    return gr.File(visible=False), gr.Textbox(visible=True)\n",
        "\n",
        "            input_type.change(toggle_input, input_type, [xml_input, xml_text])\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### 📊 What you can do:\n",
        "            - **View Structure**: See the hierarchical structure of your XML\n",
        "            - **Extract Data**: Convert XML to JSON and detect table structures\n",
        "            - **Generate Insights**: Get meaningful analysis of your XML content\n",
        "            - **Visualize**: Create charts showing tag frequencies\n",
        "            - **Clean XML**: Format and prettify your XML code\n",
        "\n",
        "            ### 🚀 Try with this sample XML:\n",
        "            ```xml\n",
        "            <catalog>\n",
        "              <book id=\"101\">\n",
        "                <author>John Doe</author>\n",
        "                <title>XML Guide</title>\n",
        "                <price>29.99</price>\n",
        "              </book>\n",
        "              <book id=\"102\">\n",
        "                <author>Jane Smith</author>\n",
        "                <title>Python Programming</title>\n",
        "                <price>39.99</price>\n",
        "              </book>\n",
        "            </catalog>\n",
        "            ```\n",
        "            \"\"\")\n",
        "\n",
        "    with gr.Tab(\"📁 XML Structure\"):\n",
        "        gr.Markdown(\"### XML Document Structure\")\n",
        "        structure_btn = gr.Button(\"Extract Structure\", variant=\"primary\")\n",
        "        structure_output = gr.Code(label=\"XML Structure\", language=\"markdown\", lines=15)\n",
        "\n",
        "    with gr.Tab(\"📊 Data Extraction\"):\n",
        "        gr.Markdown(\"### Extracted Data from XML\")\n",
        "        extract_btn = gr.Button(\"Extract Data\", variant=\"primary\")\n",
        "        with gr.Row():\n",
        "            json_output = gr.Code(label=\"JSON Representation\", language=\"json\", lines=15)\n",
        "            table_output = gr.HTML(label=\"Tabular Data\")\n",
        "\n",
        "    with gr.Tab(\"🔍 Insights\"):\n",
        "        gr.Markdown(\"### XML Insights & Analysis\")\n",
        "        insights_btn = gr.Button(\"Generate Insights\", variant=\"primary\")\n",
        "        insights_output = gr.HTML(label=\"XML Insights\")\n",
        "\n",
        "    with gr.Tab(\"📈 Visualization\"):\n",
        "        gr.Markdown(\"### XML Data Visualization\")\n",
        "        viz_btn = gr.Button(\"Create Visualization\", variant=\"primary\")\n",
        "        viz_output = gr.Plot(label=\"Tag Frequency Visualization\")\n",
        "\n",
        "    with gr.Tab(\"✨ XML Cleaner\"):\n",
        "        gr.Markdown(\"### Clean and Format XML\")\n",
        "        clean_btn = gr.Button(\"Clean and Format XML\", variant=\"primary\")\n",
        "        clean_output = gr.Code(label=\"Formatted XML\", language=\"html\", lines=15)\n",
        "\n",
        "    # Set up event handlers\n",
        "    structure_btn.click(\n",
        "        extract_xml_structure,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=structure_output\n",
        "    )\n",
        "\n",
        "    extract_btn.click(\n",
        "        extract_xml_data,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=[json_output, table_output]\n",
        "    )\n",
        "\n",
        "    insights_btn.click(\n",
        "        generate_insights,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=insights_output\n",
        "    )\n",
        "\n",
        "    viz_btn.click(\n",
        "        visualize_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=viz_output\n",
        "    )\n",
        "\n",
        "    clean_btn.click(\n",
        "        clean_xml,\n",
        "        inputs=[xml_input, input_type],\n",
        "        outputs=clean_output\n",
        "    )\n",
        "\n",
        "# For Google Colab, we need to handle the launch differently\n",
        "def launch_in_colab():\n",
        "    # Create a public link\n",
        "    demo.launch(share=True, debug=True)\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    # This will work in both Colab and local environments\n",
        "    try:\n",
        "        import google.colab\n",
        "        IN_COLAB = True\n",
        "    except:\n",
        "        IN_COLAB = False\n",
        "\n",
        "    if IN_COLAB:\n",
        "        launch_in_colab()\n",
        "    else:\n",
        "        demo.launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
