{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cbd1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5198fdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dd89c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abc', 'abc.zip', 'alpino', 'alpino.zip', 'bcp47.zip', 'biocreative_ppi', 'biocreative_ppi.zip', 'brown', 'brown.zip', 'brown_tei', 'brown_tei.zip', 'cess_cat', 'cess_cat.zip', 'cess_esp', 'cess_esp.zip', 'chat80', 'chat80.zip', 'city_database', 'city_database.zip', 'cmudict', 'cmudict.zip', 'comparative_sentences', 'comparative_sentences.zip', 'comtrans.zip', 'conll2000', 'conll2000.zip', 'conll2002', 'conll2002.zip', 'conll2007.zip', 'crubadan', 'crubadan.zip', 'dependency_treebank', 'dependency_treebank.zip', 'dolch', 'dolch.zip', 'english_wordnet', 'english_wordnet.zip', 'europarl_raw', 'europarl_raw.zip', 'extended_omw.zip', 'floresta', 'floresta.zip', 'framenet_v15', 'framenet_v15.zip', 'framenet_v17', 'framenet_v17.zip', 'gazetteers', 'gazetteers.zip', 'genesis', 'genesis.zip', 'gutenberg', 'gutenberg.zip', 'ieer', 'ieer.zip', 'inaugural', 'inaugural.zip', 'indian', 'indian.zip', 'jeita.zip', 'kimmo', 'kimmo.zip', 'knbc.zip', 'lin_thesaurus', 'lin_thesaurus.zip', 'machado.zip', 'mac_morpho', 'mac_morpho.zip', 'masc_tagged.zip', 'mock_corpus.zip', 'movie_reviews', 'movie_reviews.zip', 'mte_teip5', 'mte_teip5.zip', 'names', 'names.zip', 'nombank.1.0.zip', 'nonbreaking_prefixes', 'nonbreaking_prefixes.zip', 'nps_chat', 'nps_chat.zip', 'omw-1.4.zip', 'omw.zip', 'opinion_lexicon', 'opinion_lexicon.zip', 'panlex_swadesh.zip', 'paradigms', 'paradigms.zip', 'pe08', 'pe08.zip', 'pil', 'pil.zip', 'pl196x', 'pl196x.zip', 'ppattach', 'ppattach.zip', 'problem_reports', 'problem_reports.zip', 'product_reviews_1', 'product_reviews_1.zip', 'product_reviews_2', 'product_reviews_2.zip', 'propbank.zip', 'pros_cons', 'pros_cons.zip', 'ptb', 'ptb.zip', 'qc', 'qc.zip', 'reuters.zip', 'rte', 'rte.zip', 'semcor.zip', 'senseval', 'senseval.zip', 'sentence_polarity', 'sentence_polarity.zip', 'sentiwordnet', 'sentiwordnet.zip', 'shakespeare', 'shakespeare.zip', 'sinica_treebank', 'sinica_treebank.zip', 'smultron', 'smultron.zip', 'state_union', 'state_union.zip', 'stopwords', 'stopwords.zip', 'subjectivity', 'subjectivity.zip', 'swadesh', 'swadesh.zip', 'switchboard', 'switchboard.zip', 'timit', 'timit.zip', 'toolbox', 'toolbox.zip', 'treebank', 'treebank.zip', 'twitter_samples', 'twitter_samples.zip', 'udhr', 'udhr.zip', 'udhr2', 'udhr2.zip', 'unicode_samples', 'unicode_samples.zip', 'universal_treebanks_v20.zip', 'verbnet', 'verbnet.zip', 'verbnet3', 'verbnet3.zip', 'webtext', 'webtext.zip', 'wordnet.zip', 'wordnet2021.zip', 'wordnet2022', 'wordnet2022.zip', 'wordnet31.zip', 'wordnet_ic', 'wordnet_ic.zip', 'words', 'words.zip', 'ycoe', 'ycoe.zip']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(nltk.data.find(\"corpora\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4afd5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also create your own words\n",
    "AI = '''Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\n",
    "humans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\n",
    "problem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\n",
    "It is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\n",
    "AI could solve major challenges and crisis situations.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ef5e5e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6144f51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(AI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daaec80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "AI_tokens = word_tokenize(AI)\n",
    "AI_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad139e80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a66d65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02c2251a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines.',\n",
       " 'This is in contrast to the natural intelligence of\\nhumans and animals.',\n",
       " 'With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving.',\n",
       " 'Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.',\n",
       " 'It is probably the fastest-growing development in the World of technology and innovation.',\n",
       " 'Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "AI_sent = sent_tokenize(AI)\n",
    "AI_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0d01fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af4e0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial Intelligence refers to the intelligence of machines. This is in contrast to the natural intelligence of\\nhumans and animals. With Artificial Intelligence, machines perform functions such as learning, planning, reasoning and\\nproblem-solving. Most noteworthy, Artificial Intelligence is the simulation of human intelligence by machines.\\nIt is probably the fastest-growing development in the World of technology and innovation. Furthermore, many experts believe\\nAI could solve major challenges and crisis situations.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "AI_blank = blankline_tokenize(AI)\n",
    "AI_blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "018aaac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AI_blank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb4dbcaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence,',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning,',\n",
       " 'planning,',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem-solving.',\n",
       " 'Most',\n",
       " 'noteworthy,',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest-growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation.',\n",
       " 'Furthermore,',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "wt = WhitespaceTokenizer().tokenize(AI)\n",
    "wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb03dca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9bda205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good apple cost $ 3.56 in Hyderabad.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"Good apple cost $ 3.56 in Hyderabad.\"\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "215b3805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Good', 'apple', 'cost', '$', '3', '.', '56', 'in', 'Hyderabad', '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d414b167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'Intelligence',\n",
       " 'refers',\n",
       " 'to',\n",
       " 'the',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'machines',\n",
       " '.',\n",
       " 'This',\n",
       " 'is',\n",
       " 'in',\n",
       " 'contrast',\n",
       " 'to',\n",
       " 'the',\n",
       " 'natural',\n",
       " 'intelligence',\n",
       " 'of',\n",
       " 'humans',\n",
       " 'and',\n",
       " 'animals',\n",
       " '.',\n",
       " 'With',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " ',',\n",
       " 'machines',\n",
       " 'perform',\n",
       " 'functions',\n",
       " 'such',\n",
       " 'as',\n",
       " 'learning',\n",
       " ',',\n",
       " 'planning',\n",
       " ',',\n",
       " 'reasoning',\n",
       " 'and',\n",
       " 'problem',\n",
       " '-',\n",
       " 'solving',\n",
       " '.',\n",
       " 'Most',\n",
       " 'noteworthy',\n",
       " ',',\n",
       " 'Artificial',\n",
       " 'Intelligence',\n",
       " 'is',\n",
       " 'the',\n",
       " 'simulation',\n",
       " 'of',\n",
       " 'human',\n",
       " 'intelligence',\n",
       " 'by',\n",
       " 'machines',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'probably',\n",
       " 'the',\n",
       " 'fastest',\n",
       " '-',\n",
       " 'growing',\n",
       " 'development',\n",
       " 'in',\n",
       " 'the',\n",
       " 'World',\n",
       " 'of',\n",
       " 'technology',\n",
       " 'and',\n",
       " 'innovation',\n",
       " '.',\n",
       " 'Furthermore',\n",
       " ',',\n",
       " 'many',\n",
       " 'experts',\n",
       " 'believe',\n",
       " 'AI',\n",
       " 'could',\n",
       " 'solve',\n",
       " 'major',\n",
       " 'challenges',\n",
       " 'and',\n",
       " 'crisis',\n",
       " 'situations',\n",
       " '.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_p = wordpunct_tokenize(AI)\n",
    "w_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8b2e6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9afc1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bb29a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams, trigrams, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dcc9f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'are', 'learners', 'of', 'FSDS', 'Course', 'at', '10:00', 'am']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"We are learners of FSDS Course at 10:00 am\"\n",
    "quotes_tokens = nltk.word_tokenize(string)\n",
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "356e25f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are learners of FSDS Course at 10:00 am'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b372af83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We', 'are', 'learners', 'of', 'FSDS', 'Course', 'at', '10:00', 'am']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "314faefa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(quotes_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74fd9c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'are'),\n",
       " ('are', 'learners'),\n",
       " ('learners', 'of'),\n",
       " ('of', 'FSDS'),\n",
       " ('FSDS', 'Course'),\n",
       " ('Course', 'at'),\n",
       " ('at', '10:00'),\n",
       " ('10:00', 'am')]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_bigrams = list(nltk.bigrams(quotes_tokens))\n",
    "quotes_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d1a1f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'are', 'learners'),\n",
       " ('are', 'learners', 'of'),\n",
       " ('learners', 'of', 'FSDS'),\n",
       " ('of', 'FSDS', 'Course'),\n",
       " ('FSDS', 'Course', 'at'),\n",
       " ('Course', 'at', '10:00'),\n",
       " ('at', '10:00', 'am')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_trigrams = list(nltk.trigrams(quotes_tokens))\n",
    "quotes_trigrams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c1cb9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'are', 'learners', 'of', 'FSDS', 'Course', 'at'),\n",
       " ('are', 'learners', 'of', 'FSDS', 'Course', 'at', '10:00'),\n",
       " ('learners', 'of', 'FSDS', 'Course', 'at', '10:00', 'am')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_ngrams = list(nltk.ngrams(quotes_tokens, 7))\n",
    "quotes_ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dc205c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_ngrams_1 = list(nltk.ngrams(quotes_tokens,11))\n",
    "quotes_ngrams_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2aa6fcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer\n",
    "pst = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8fbbb58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'affect'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"affection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f74492fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"playing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "586ce706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maximum'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"maximum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "035988a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = [\"give\",\"giving\",\"given\",\"gave\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15c268e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n",
      "thinking:think\n",
      "shalu:shalu\n",
      "shalu shalini:shalu shalini\n",
      "shalini:shalini\n"
     ]
    }
   ],
   "source": [
    "words_to_stem = [\"give\",\"giving\",\"given\",\"gave\",\"thinking\",\"shalu\",\"shalu shalini\",\"shalini\"]\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +pst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1c9133b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:giv\n",
      "giving:giv\n",
      "given:giv\n",
      "gave:gav\n",
      "thinking:think\n",
      "shalu:shalu\n",
      "shalu shalini:shalu shalini\n",
      "shalini:shalin\n"
     ]
    }
   ],
   "source": [
    "from nltk import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +lst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d1d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give:give\n",
      "giving:give\n",
      "given:given\n",
      "gave:gave\n",
      "thinking:think\n",
      "shalu:shalu\n",
      "shalu shalini:shalu shalini\n",
      "shalini:shalini\n"
     ]
    }
   ],
   "source": [
    "from nltk import SnowballStemmer\n",
    "sbst = SnowballStemmer(\"english\")\n",
    "\n",
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +sbst.stem(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "94928330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'autobahn'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"german\")\n",
    "stemmer.stem(\"Autobahnen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bc8b386",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "word_lem = WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "514f1bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['give',\n",
       " 'giving',\n",
       " 'given',\n",
       " 'gave',\n",
       " 'thinking',\n",
       " 'shalu',\n",
       " 'shalu shalini',\n",
       " 'shalini']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_to_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f166a60",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "WordNetLemmatizer.lemmatize() missing 1 required positional argument: 'word'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m words_to_stem:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(words+ \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m +\u001b[43mword_lem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlemmatize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: WordNetLemmatizer.lemmatize() missing 1 required positional argument: 'word'"
     ]
    }
   ],
   "source": [
    "for words in words_to_stem:\n",
    "    print(words+ \":\" +word_lem.lemmatize(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ed3b55",
   "metadata": {},
   "source": [
    "# STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3029983a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b0cefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbd44eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au',\n",
       " 'aux',\n",
       " 'avec',\n",
       " 'ce',\n",
       " 'ces',\n",
       " 'dans',\n",
       " 'de',\n",
       " 'des',\n",
       " 'du',\n",
       " 'elle',\n",
       " 'en',\n",
       " 'et',\n",
       " 'eux',\n",
       " 'il',\n",
       " 'ils',\n",
       " 'je',\n",
       " 'la',\n",
       " 'le',\n",
       " 'les',\n",
       " 'leur',\n",
       " 'lui',\n",
       " 'ma',\n",
       " 'mais',\n",
       " 'me',\n",
       " 'même',\n",
       " 'mes',\n",
       " 'moi',\n",
       " 'mon',\n",
       " 'ne',\n",
       " 'nos',\n",
       " 'notre',\n",
       " 'nous',\n",
       " 'on',\n",
       " 'ou',\n",
       " 'par',\n",
       " 'pas',\n",
       " 'pour',\n",
       " 'qu',\n",
       " 'que',\n",
       " 'qui',\n",
       " 'sa',\n",
       " 'se',\n",
       " 'ses',\n",
       " 'son',\n",
       " 'sur',\n",
       " 'ta',\n",
       " 'te',\n",
       " 'tes',\n",
       " 'toi',\n",
       " 'ton',\n",
       " 'tu',\n",
       " 'un',\n",
       " 'une',\n",
       " 'vos',\n",
       " 'votre',\n",
       " 'vous',\n",
       " 'c',\n",
       " 'd',\n",
       " 'j',\n",
       " 'l',\n",
       " 'à',\n",
       " 'm',\n",
       " 'n',\n",
       " 's',\n",
       " 't',\n",
       " 'y',\n",
       " 'été',\n",
       " 'étée',\n",
       " 'étées',\n",
       " 'étés',\n",
       " 'étant',\n",
       " 'étante',\n",
       " 'étants',\n",
       " 'étantes',\n",
       " 'suis',\n",
       " 'es',\n",
       " 'est',\n",
       " 'sommes',\n",
       " 'êtes',\n",
       " 'sont',\n",
       " 'serai',\n",
       " 'seras',\n",
       " 'sera',\n",
       " 'serons',\n",
       " 'serez',\n",
       " 'seront',\n",
       " 'serais',\n",
       " 'serait',\n",
       " 'serions',\n",
       " 'seriez',\n",
       " 'seraient',\n",
       " 'étais',\n",
       " 'était',\n",
       " 'étions',\n",
       " 'étiez',\n",
       " 'étaient',\n",
       " 'fus',\n",
       " 'fut',\n",
       " 'fûmes',\n",
       " 'fûtes',\n",
       " 'furent',\n",
       " 'sois',\n",
       " 'soit',\n",
       " 'soyons',\n",
       " 'soyez',\n",
       " 'soient',\n",
       " 'fusse',\n",
       " 'fusses',\n",
       " 'fût',\n",
       " 'fussions',\n",
       " 'fussiez',\n",
       " 'fussent',\n",
       " 'ayant',\n",
       " 'ayante',\n",
       " 'ayantes',\n",
       " 'ayants',\n",
       " 'eu',\n",
       " 'eue',\n",
       " 'eues',\n",
       " 'eus',\n",
       " 'ai',\n",
       " 'as',\n",
       " 'avons',\n",
       " 'avez',\n",
       " 'ont',\n",
       " 'aurai',\n",
       " 'auras',\n",
       " 'aura',\n",
       " 'aurons',\n",
       " 'aurez',\n",
       " 'auront',\n",
       " 'aurais',\n",
       " 'aurait',\n",
       " 'aurions',\n",
       " 'auriez',\n",
       " 'auraient',\n",
       " 'avais',\n",
       " 'avait',\n",
       " 'avions',\n",
       " 'aviez',\n",
       " 'avaient',\n",
       " 'eut',\n",
       " 'eûmes',\n",
       " 'eûtes',\n",
       " 'eurent',\n",
       " 'aie',\n",
       " 'aies',\n",
       " 'ait',\n",
       " 'ayons',\n",
       " 'ayez',\n",
       " 'aient',\n",
       " 'eusse',\n",
       " 'eusses',\n",
       " 'eût',\n",
       " 'eussions',\n",
       " 'eussiez',\n",
       " 'eussent']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"french\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b31e91f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"french\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fea4cc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aber',\n",
       " 'alle',\n",
       " 'allem',\n",
       " 'allen',\n",
       " 'aller',\n",
       " 'alles',\n",
       " 'als',\n",
       " 'also',\n",
       " 'am',\n",
       " 'an',\n",
       " 'ander',\n",
       " 'andere',\n",
       " 'anderem',\n",
       " 'anderen',\n",
       " 'anderer',\n",
       " 'anderes',\n",
       " 'anderm',\n",
       " 'andern',\n",
       " 'anderr',\n",
       " 'anders',\n",
       " 'auch',\n",
       " 'auf',\n",
       " 'aus',\n",
       " 'bei',\n",
       " 'bin',\n",
       " 'bis',\n",
       " 'bist',\n",
       " 'da',\n",
       " 'damit',\n",
       " 'dann',\n",
       " 'der',\n",
       " 'den',\n",
       " 'des',\n",
       " 'dem',\n",
       " 'die',\n",
       " 'das',\n",
       " 'dass',\n",
       " 'daß',\n",
       " 'derselbe',\n",
       " 'derselben',\n",
       " 'denselben',\n",
       " 'desselben',\n",
       " 'demselben',\n",
       " 'dieselbe',\n",
       " 'dieselben',\n",
       " 'dasselbe',\n",
       " 'dazu',\n",
       " 'dein',\n",
       " 'deine',\n",
       " 'deinem',\n",
       " 'deinen',\n",
       " 'deiner',\n",
       " 'deines',\n",
       " 'denn',\n",
       " 'derer',\n",
       " 'dessen',\n",
       " 'dich',\n",
       " 'dir',\n",
       " 'du',\n",
       " 'dies',\n",
       " 'diese',\n",
       " 'diesem',\n",
       " 'diesen',\n",
       " 'dieser',\n",
       " 'dieses',\n",
       " 'doch',\n",
       " 'dort',\n",
       " 'durch',\n",
       " 'ein',\n",
       " 'eine',\n",
       " 'einem',\n",
       " 'einen',\n",
       " 'einer',\n",
       " 'eines',\n",
       " 'einig',\n",
       " 'einige',\n",
       " 'einigem',\n",
       " 'einigen',\n",
       " 'einiger',\n",
       " 'einiges',\n",
       " 'einmal',\n",
       " 'er',\n",
       " 'ihn',\n",
       " 'ihm',\n",
       " 'es',\n",
       " 'etwas',\n",
       " 'euer',\n",
       " 'eure',\n",
       " 'eurem',\n",
       " 'euren',\n",
       " 'eurer',\n",
       " 'eures',\n",
       " 'für',\n",
       " 'gegen',\n",
       " 'gewesen',\n",
       " 'hab',\n",
       " 'habe',\n",
       " 'haben',\n",
       " 'hat',\n",
       " 'hatte',\n",
       " 'hatten',\n",
       " 'hier',\n",
       " 'hin',\n",
       " 'hinter',\n",
       " 'ich',\n",
       " 'mich',\n",
       " 'mir',\n",
       " 'ihr',\n",
       " 'ihre',\n",
       " 'ihrem',\n",
       " 'ihren',\n",
       " 'ihrer',\n",
       " 'ihres',\n",
       " 'euch',\n",
       " 'im',\n",
       " 'in',\n",
       " 'indem',\n",
       " 'ins',\n",
       " 'ist',\n",
       " 'jede',\n",
       " 'jedem',\n",
       " 'jeden',\n",
       " 'jeder',\n",
       " 'jedes',\n",
       " 'jene',\n",
       " 'jenem',\n",
       " 'jenen',\n",
       " 'jener',\n",
       " 'jenes',\n",
       " 'jetzt',\n",
       " 'kann',\n",
       " 'kein',\n",
       " 'keine',\n",
       " 'keinem',\n",
       " 'keinen',\n",
       " 'keiner',\n",
       " 'keines',\n",
       " 'können',\n",
       " 'könnte',\n",
       " 'machen',\n",
       " 'man',\n",
       " 'manche',\n",
       " 'manchem',\n",
       " 'manchen',\n",
       " 'mancher',\n",
       " 'manches',\n",
       " 'mein',\n",
       " 'meine',\n",
       " 'meinem',\n",
       " 'meinen',\n",
       " 'meiner',\n",
       " 'meines',\n",
       " 'mit',\n",
       " 'muss',\n",
       " 'musste',\n",
       " 'nach',\n",
       " 'nicht',\n",
       " 'nichts',\n",
       " 'noch',\n",
       " 'nun',\n",
       " 'nur',\n",
       " 'ob',\n",
       " 'oder',\n",
       " 'ohne',\n",
       " 'sehr',\n",
       " 'sein',\n",
       " 'seine',\n",
       " 'seinem',\n",
       " 'seinen',\n",
       " 'seiner',\n",
       " 'seines',\n",
       " 'selbst',\n",
       " 'sich',\n",
       " 'sie',\n",
       " 'ihnen',\n",
       " 'sind',\n",
       " 'so',\n",
       " 'solche',\n",
       " 'solchem',\n",
       " 'solchen',\n",
       " 'solcher',\n",
       " 'solches',\n",
       " 'soll',\n",
       " 'sollte',\n",
       " 'sondern',\n",
       " 'sonst',\n",
       " 'über',\n",
       " 'um',\n",
       " 'und',\n",
       " 'uns',\n",
       " 'unsere',\n",
       " 'unserem',\n",
       " 'unseren',\n",
       " 'unser',\n",
       " 'unseres',\n",
       " 'unter',\n",
       " 'viel',\n",
       " 'vom',\n",
       " 'von',\n",
       " 'vor',\n",
       " 'während',\n",
       " 'war',\n",
       " 'waren',\n",
       " 'warst',\n",
       " 'was',\n",
       " 'weg',\n",
       " 'weil',\n",
       " 'weiter',\n",
       " 'welche',\n",
       " 'welchem',\n",
       " 'welchen',\n",
       " 'welcher',\n",
       " 'welches',\n",
       " 'wenn',\n",
       " 'werde',\n",
       " 'werden',\n",
       " 'wie',\n",
       " 'wieder',\n",
       " 'will',\n",
       " 'wir',\n",
       " 'wird',\n",
       " 'wirst',\n",
       " 'wo',\n",
       " 'wollen',\n",
       " 'wollte',\n",
       " 'würde',\n",
       " 'würden',\n",
       " 'zu',\n",
       " 'zum',\n",
       " 'zur',\n",
       " 'zwar',\n",
       " 'zwischen']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71f72d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"german\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['一',\n",
       " '一下',\n",
       " '一些',\n",
       " '一切',\n",
       " '一则',\n",
       " '一天',\n",
       " '一定',\n",
       " '一方面',\n",
       " '一旦',\n",
       " '一时',\n",
       " '一来',\n",
       " '一样',\n",
       " '一次',\n",
       " '一片',\n",
       " '一直',\n",
       " '一致',\n",
       " '一般',\n",
       " '一起',\n",
       " '一边',\n",
       " '一面',\n",
       " '万一',\n",
       " '上下',\n",
       " '上升',\n",
       " '上去',\n",
       " '上来',\n",
       " '上述',\n",
       " '上面',\n",
       " '下列',\n",
       " '下去',\n",
       " '下来',\n",
       " '下面',\n",
       " '不一',\n",
       " '不久',\n",
       " '不仅',\n",
       " '不会',\n",
       " '不但',\n",
       " '不光',\n",
       " '不单',\n",
       " '不变',\n",
       " '不只',\n",
       " '不可',\n",
       " '不同',\n",
       " '不够',\n",
       " '不如',\n",
       " '不得',\n",
       " '不怕',\n",
       " '不惟',\n",
       " '不成',\n",
       " '不拘',\n",
       " '不敢',\n",
       " '不断',\n",
       " '不是',\n",
       " '不比',\n",
       " '不然',\n",
       " '不特',\n",
       " '不独',\n",
       " '不管',\n",
       " '不能',\n",
       " '不要',\n",
       " '不论',\n",
       " '不足',\n",
       " '不过',\n",
       " '不问',\n",
       " '与',\n",
       " '与其',\n",
       " '与否',\n",
       " '与此同时',\n",
       " '专门',\n",
       " '且',\n",
       " '两者',\n",
       " '严格',\n",
       " '严重',\n",
       " '个',\n",
       " '个人',\n",
       " '个别',\n",
       " '中小',\n",
       " '中间',\n",
       " '丰富',\n",
       " '临',\n",
       " '为',\n",
       " '为主',\n",
       " '为了',\n",
       " '为什么',\n",
       " '为什麽',\n",
       " '为何',\n",
       " '为着',\n",
       " '主张',\n",
       " '主要',\n",
       " '举行',\n",
       " '乃',\n",
       " '乃至',\n",
       " '么',\n",
       " '之',\n",
       " '之一',\n",
       " '之前',\n",
       " '之后',\n",
       " '之後',\n",
       " '之所以',\n",
       " '之类',\n",
       " '乌乎',\n",
       " '乎',\n",
       " '乘',\n",
       " '也',\n",
       " '也好',\n",
       " '也是',\n",
       " '也罢',\n",
       " '了',\n",
       " '了解',\n",
       " '争取',\n",
       " '于',\n",
       " '于是',\n",
       " '于是乎',\n",
       " '云云',\n",
       " '互相',\n",
       " '产生',\n",
       " '人们',\n",
       " '人家',\n",
       " '什么',\n",
       " '什么样',\n",
       " '什麽',\n",
       " '今后',\n",
       " '今天',\n",
       " '今年',\n",
       " '今後',\n",
       " '仍然',\n",
       " '从',\n",
       " '从事',\n",
       " '从而',\n",
       " '他',\n",
       " '他人',\n",
       " '他们',\n",
       " '他的',\n",
       " '代替',\n",
       " '以',\n",
       " '以上',\n",
       " '以下',\n",
       " '以为',\n",
       " '以便',\n",
       " '以免',\n",
       " '以前',\n",
       " '以及',\n",
       " '以后',\n",
       " '以外',\n",
       " '以後',\n",
       " '以来',\n",
       " '以至',\n",
       " '以至于',\n",
       " '以致',\n",
       " '们',\n",
       " '任',\n",
       " '任何',\n",
       " '任凭',\n",
       " '任务',\n",
       " '企图',\n",
       " '伟大',\n",
       " '似乎',\n",
       " '似的',\n",
       " '但',\n",
       " '但是',\n",
       " '何',\n",
       " '何况',\n",
       " '何处',\n",
       " '何时',\n",
       " '作为',\n",
       " '你',\n",
       " '你们',\n",
       " '你的',\n",
       " '使得',\n",
       " '使用',\n",
       " '例如',\n",
       " '依',\n",
       " '依照',\n",
       " '依靠',\n",
       " '促进',\n",
       " '保持',\n",
       " '俺',\n",
       " '俺们',\n",
       " '倘',\n",
       " '倘使',\n",
       " '倘或',\n",
       " '倘然',\n",
       " '倘若',\n",
       " '假使',\n",
       " '假如',\n",
       " '假若',\n",
       " '做到',\n",
       " '像',\n",
       " '允许',\n",
       " '充分',\n",
       " '先后',\n",
       " '先後',\n",
       " '先生',\n",
       " '全部',\n",
       " '全面',\n",
       " '兮',\n",
       " '共同',\n",
       " '关于',\n",
       " '其',\n",
       " '其一',\n",
       " '其中',\n",
       " '其二',\n",
       " '其他',\n",
       " '其余',\n",
       " '其它',\n",
       " '其实',\n",
       " '其次',\n",
       " '具体',\n",
       " '具体地说',\n",
       " '具体说来',\n",
       " '具有',\n",
       " '再者',\n",
       " '再说',\n",
       " '冒',\n",
       " '冲',\n",
       " '决定',\n",
       " '况且',\n",
       " '准备',\n",
       " '几',\n",
       " '几乎',\n",
       " '几时',\n",
       " '凭',\n",
       " '凭借',\n",
       " '出去',\n",
       " '出来',\n",
       " '出现',\n",
       " '分别',\n",
       " '则',\n",
       " '别',\n",
       " '别的',\n",
       " '别说',\n",
       " '到',\n",
       " '前后',\n",
       " '前者',\n",
       " '前进',\n",
       " '前面',\n",
       " '加之',\n",
       " '加以',\n",
       " '加入',\n",
       " '加强',\n",
       " '十分',\n",
       " '即',\n",
       " '即令',\n",
       " '即使',\n",
       " '即便',\n",
       " '即或',\n",
       " '即若',\n",
       " '却不',\n",
       " '原来',\n",
       " '又',\n",
       " '及',\n",
       " '及其',\n",
       " '及时',\n",
       " '及至',\n",
       " '双方',\n",
       " '反之',\n",
       " '反应',\n",
       " '反映',\n",
       " '反过来',\n",
       " '反过来说',\n",
       " '取得',\n",
       " '受到',\n",
       " '变成',\n",
       " '另',\n",
       " '另一方面',\n",
       " '另外',\n",
       " '只是',\n",
       " '只有',\n",
       " '只要',\n",
       " '只限',\n",
       " '叫',\n",
       " '叫做',\n",
       " '召开',\n",
       " '叮咚',\n",
       " '可',\n",
       " '可以',\n",
       " '可是',\n",
       " '可能',\n",
       " '可见',\n",
       " '各',\n",
       " '各个',\n",
       " '各人',\n",
       " '各位',\n",
       " '各地',\n",
       " '各种',\n",
       " '各级',\n",
       " '各自',\n",
       " '合理',\n",
       " '同',\n",
       " '同一',\n",
       " '同时',\n",
       " '同样',\n",
       " '后来',\n",
       " '后面',\n",
       " '向',\n",
       " '向着',\n",
       " '吓',\n",
       " '吗',\n",
       " '否则',\n",
       " '吧',\n",
       " '吧哒',\n",
       " '吱',\n",
       " '呀',\n",
       " '呃',\n",
       " '呕',\n",
       " '呗',\n",
       " '呜',\n",
       " '呜呼',\n",
       " '呢',\n",
       " '周围',\n",
       " '呵',\n",
       " '呸',\n",
       " '呼哧',\n",
       " '咋',\n",
       " '和',\n",
       " '咚',\n",
       " '咦',\n",
       " '咱',\n",
       " '咱们',\n",
       " '咳',\n",
       " '哇',\n",
       " '哈',\n",
       " '哈哈',\n",
       " '哉',\n",
       " '哎',\n",
       " '哎呀',\n",
       " '哎哟',\n",
       " '哗',\n",
       " '哟',\n",
       " '哦',\n",
       " '哩',\n",
       " '哪',\n",
       " '哪个',\n",
       " '哪些',\n",
       " '哪儿',\n",
       " '哪天',\n",
       " '哪年',\n",
       " '哪怕',\n",
       " '哪样',\n",
       " '哪边',\n",
       " '哪里',\n",
       " '哼',\n",
       " '哼唷',\n",
       " '唉',\n",
       " '啊',\n",
       " '啐',\n",
       " '啥',\n",
       " '啦',\n",
       " '啪达',\n",
       " '喂',\n",
       " '喏',\n",
       " '喔唷',\n",
       " '嗡嗡',\n",
       " '嗬',\n",
       " '嗯',\n",
       " '嗳',\n",
       " '嘎',\n",
       " '嘎登',\n",
       " '嘘',\n",
       " '嘛',\n",
       " '嘻',\n",
       " '嘿',\n",
       " '因',\n",
       " '因为',\n",
       " '因此',\n",
       " '因而',\n",
       " '固然',\n",
       " '在',\n",
       " '在下',\n",
       " '地',\n",
       " '坚决',\n",
       " '坚持',\n",
       " '基本',\n",
       " '处理',\n",
       " '复杂',\n",
       " '多',\n",
       " '多少',\n",
       " '多数',\n",
       " '多次',\n",
       " '大力',\n",
       " '大多数',\n",
       " '大大',\n",
       " '大家',\n",
       " '大批',\n",
       " '大约',\n",
       " '大量',\n",
       " '失去',\n",
       " '她',\n",
       " '她们',\n",
       " '她的',\n",
       " '好的',\n",
       " '好象',\n",
       " '如',\n",
       " '如上所述',\n",
       " '如下',\n",
       " '如何',\n",
       " '如其',\n",
       " '如果',\n",
       " '如此',\n",
       " '如若',\n",
       " '存在',\n",
       " '宁',\n",
       " '宁可',\n",
       " '宁愿',\n",
       " '宁肯',\n",
       " '它',\n",
       " '它们',\n",
       " '它们的',\n",
       " '它的',\n",
       " '安全',\n",
       " '完全',\n",
       " '完成',\n",
       " '实现',\n",
       " '实际',\n",
       " '宣布',\n",
       " '容易',\n",
       " '密切',\n",
       " '对',\n",
       " '对于',\n",
       " '对应',\n",
       " '将',\n",
       " '少数',\n",
       " '尔后',\n",
       " '尚且',\n",
       " '尤其',\n",
       " '就',\n",
       " '就是',\n",
       " '就是说',\n",
       " '尽',\n",
       " '尽管',\n",
       " '属于',\n",
       " '岂但',\n",
       " '左右',\n",
       " '巨大',\n",
       " '巩固',\n",
       " '己',\n",
       " '已经',\n",
       " '帮助',\n",
       " '常常',\n",
       " '并',\n",
       " '并不',\n",
       " '并不是',\n",
       " '并且',\n",
       " '并没有',\n",
       " '广大',\n",
       " '广泛',\n",
       " '应当',\n",
       " '应用',\n",
       " '应该',\n",
       " '开外',\n",
       " '开始',\n",
       " '开展',\n",
       " '引起',\n",
       " '强烈',\n",
       " '强调',\n",
       " '归',\n",
       " '当',\n",
       " '当前',\n",
       " '当时',\n",
       " '当然',\n",
       " '当着',\n",
       " '形成',\n",
       " '彻底',\n",
       " '彼',\n",
       " '彼此',\n",
       " '往',\n",
       " '往往',\n",
       " '待',\n",
       " '後来',\n",
       " '後面',\n",
       " '得',\n",
       " '得出',\n",
       " '得到',\n",
       " '心里',\n",
       " '必然',\n",
       " '必要',\n",
       " '必须',\n",
       " '怎',\n",
       " '怎么',\n",
       " '怎么办',\n",
       " '怎么样',\n",
       " '怎样',\n",
       " '怎麽',\n",
       " '总之',\n",
       " '总是',\n",
       " '总的来看',\n",
       " '总的来说',\n",
       " '总的说来',\n",
       " '总结',\n",
       " '总而言之',\n",
       " '恰恰相反',\n",
       " '您',\n",
       " '意思',\n",
       " '愿意',\n",
       " '慢说',\n",
       " '成为',\n",
       " '我',\n",
       " '我们',\n",
       " '我的',\n",
       " '或',\n",
       " '或是',\n",
       " '或者',\n",
       " '战斗',\n",
       " '所',\n",
       " '所以',\n",
       " '所有',\n",
       " '所谓',\n",
       " '打',\n",
       " '扩大',\n",
       " '把',\n",
       " '抑或',\n",
       " '拿',\n",
       " '按',\n",
       " '按照',\n",
       " '换句话说',\n",
       " '换言之',\n",
       " '据',\n",
       " '掌握',\n",
       " '接着',\n",
       " '接著',\n",
       " '故',\n",
       " '故此',\n",
       " '整个',\n",
       " '方便',\n",
       " '方面',\n",
       " '旁人',\n",
       " '无宁',\n",
       " '无法',\n",
       " '无论',\n",
       " '既',\n",
       " '既是',\n",
       " '既然',\n",
       " '时候',\n",
       " '明显',\n",
       " '明确',\n",
       " '是',\n",
       " '是否',\n",
       " '是的',\n",
       " '显然',\n",
       " '显著',\n",
       " '普通',\n",
       " '普遍',\n",
       " '更加',\n",
       " '曾经',\n",
       " '替',\n",
       " '最后',\n",
       " '最大',\n",
       " '最好',\n",
       " '最後',\n",
       " '最近',\n",
       " '最高',\n",
       " '有',\n",
       " '有些',\n",
       " '有关',\n",
       " '有利',\n",
       " '有力',\n",
       " '有所',\n",
       " '有效',\n",
       " '有时',\n",
       " '有点',\n",
       " '有的',\n",
       " '有着',\n",
       " '有著',\n",
       " '望',\n",
       " '朝',\n",
       " '朝着',\n",
       " '本',\n",
       " '本着',\n",
       " '来',\n",
       " '来着',\n",
       " '极了',\n",
       " '构成',\n",
       " '果然',\n",
       " '果真',\n",
       " '某',\n",
       " '某个',\n",
       " '某些',\n",
       " '根据',\n",
       " '根本',\n",
       " '欢迎',\n",
       " '正在',\n",
       " '正如',\n",
       " '正常',\n",
       " '此',\n",
       " '此外',\n",
       " '此时',\n",
       " '此间',\n",
       " '毋宁',\n",
       " '每',\n",
       " '每个',\n",
       " '每天',\n",
       " '每年',\n",
       " '每当',\n",
       " '比',\n",
       " '比如',\n",
       " '比方',\n",
       " '比较',\n",
       " '毫不',\n",
       " '没有',\n",
       " '沿',\n",
       " '沿着',\n",
       " '注意',\n",
       " '深入',\n",
       " '清楚',\n",
       " '满足',\n",
       " '漫说',\n",
       " '焉',\n",
       " '然则',\n",
       " '然后',\n",
       " '然後',\n",
       " '然而',\n",
       " '照',\n",
       " '照着',\n",
       " '特别是',\n",
       " '特殊',\n",
       " '特点',\n",
       " '现代',\n",
       " '现在',\n",
       " '甚么',\n",
       " '甚而',\n",
       " '甚至',\n",
       " '用',\n",
       " '由',\n",
       " '由于',\n",
       " '由此可见',\n",
       " '的',\n",
       " '的话',\n",
       " '目前',\n",
       " '直到',\n",
       " '直接',\n",
       " '相似',\n",
       " '相信',\n",
       " '相反',\n",
       " '相同',\n",
       " '相对',\n",
       " '相对而言',\n",
       " '相应',\n",
       " '相当',\n",
       " '相等',\n",
       " '省得',\n",
       " '看出',\n",
       " '看到',\n",
       " '看来',\n",
       " '看看',\n",
       " '看见',\n",
       " '真是',\n",
       " '真正',\n",
       " '着',\n",
       " '着呢',\n",
       " '矣',\n",
       " '知道',\n",
       " '确定',\n",
       " '离',\n",
       " '积极',\n",
       " '移动',\n",
       " '突出',\n",
       " '突然',\n",
       " '立即',\n",
       " '第',\n",
       " '等',\n",
       " '等等',\n",
       " '管',\n",
       " '紧接着',\n",
       " '纵',\n",
       " '纵令',\n",
       " '纵使',\n",
       " '纵然',\n",
       " '练习',\n",
       " '组成',\n",
       " '经',\n",
       " '经常',\n",
       " '经过',\n",
       " '结合',\n",
       " '结果',\n",
       " '给',\n",
       " '绝对',\n",
       " '继续',\n",
       " '继而',\n",
       " '维持',\n",
       " '综上所述',\n",
       " '罢了',\n",
       " '考虑',\n",
       " '者',\n",
       " '而',\n",
       " '而且',\n",
       " '而况',\n",
       " '而外',\n",
       " '而已',\n",
       " '而是',\n",
       " '而言',\n",
       " '联系',\n",
       " '能',\n",
       " '能否',\n",
       " '能够',\n",
       " '腾',\n",
       " '自',\n",
       " '自个儿',\n",
       " '自从',\n",
       " '自各儿',\n",
       " '自家',\n",
       " '自己',\n",
       " '自身',\n",
       " '至',\n",
       " '至于',\n",
       " '良好',\n",
       " '若',\n",
       " '若是',\n",
       " '若非',\n",
       " '范围',\n",
       " '莫若',\n",
       " '获得',\n",
       " '虽',\n",
       " '虽则',\n",
       " '虽然',\n",
       " '虽说',\n",
       " '行为',\n",
       " '行动',\n",
       " '表明',\n",
       " '表示',\n",
       " '被',\n",
       " '要',\n",
       " '要不',\n",
       " '要不是',\n",
       " '要不然',\n",
       " '要么',\n",
       " '要是',\n",
       " '要求',\n",
       " '规定',\n",
       " '觉得',\n",
       " '认为',\n",
       " '认真',\n",
       " '认识',\n",
       " '让',\n",
       " '许多',\n",
       " '论',\n",
       " '设使',\n",
       " '设若',\n",
       " '该',\n",
       " '说明',\n",
       " '诸位',\n",
       " '谁',\n",
       " '谁知',\n",
       " '赶',\n",
       " '起',\n",
       " '起来',\n",
       " '起见',\n",
       " '趁',\n",
       " '趁着',\n",
       " '越是',\n",
       " '跟',\n",
       " '转动',\n",
       " '转变',\n",
       " '转贴',\n",
       " '较',\n",
       " '较之',\n",
       " '边',\n",
       " '达到',\n",
       " '迅速',\n",
       " '过',\n",
       " '过去',\n",
       " '过来',\n",
       " '运用',\n",
       " '还是',\n",
       " '还有',\n",
       " '这',\n",
       " '这个',\n",
       " '这么',\n",
       " '这么些',\n",
       " '这么样',\n",
       " '这么点儿',\n",
       " '这些',\n",
       " '这会儿',\n",
       " '这儿',\n",
       " '这就是说',\n",
       " '这时',\n",
       " '这样',\n",
       " '这点',\n",
       " '这种',\n",
       " '这边',\n",
       " '这里',\n",
       " '这麽',\n",
       " '进入',\n",
       " '进步',\n",
       " '进而',\n",
       " '进行',\n",
       " '连',\n",
       " '连同',\n",
       " '适应',\n",
       " '适当',\n",
       " '适用',\n",
       " '逐步',\n",
       " '逐渐',\n",
       " '通常',\n",
       " '通过',\n",
       " '造成',\n",
       " '遇到',\n",
       " '遭到',\n",
       " '避免',\n",
       " '那',\n",
       " '那个',\n",
       " '那么',\n",
       " '那么些',\n",
       " '那么样',\n",
       " '那些',\n",
       " '那会儿',\n",
       " '那儿',\n",
       " '那时',\n",
       " '那样',\n",
       " '那边',\n",
       " '那里',\n",
       " '那麽',\n",
       " '部分',\n",
       " '鄙人',\n",
       " '采取',\n",
       " '里面',\n",
       " '重大',\n",
       " '重新',\n",
       " '重要',\n",
       " '鉴于',\n",
       " '问题',\n",
       " '防止',\n",
       " '阿',\n",
       " '附近',\n",
       " '限制',\n",
       " '除',\n",
       " '除了',\n",
       " '除此之外',\n",
       " '除非',\n",
       " '随',\n",
       " '随着',\n",
       " '随著',\n",
       " '集中',\n",
       " '需要',\n",
       " '非但',\n",
       " '非常',\n",
       " '非徒',\n",
       " '靠',\n",
       " '顺',\n",
       " '顺着',\n",
       " '首先',\n",
       " '高兴',\n",
       " '是不是']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44690400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "841"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"chinese\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "686e6b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['அங்கு',\n",
       " 'அங்கே',\n",
       " 'அடுத்த',\n",
       " 'அதனால்',\n",
       " 'அதன்',\n",
       " 'அதற்கு',\n",
       " 'அதிக',\n",
       " 'அதில்',\n",
       " 'அது',\n",
       " 'அதே',\n",
       " 'அதை',\n",
       " 'அந்த',\n",
       " 'அந்தக்',\n",
       " 'அந்தப்',\n",
       " 'அன்று',\n",
       " 'அல்லது',\n",
       " 'அவன்',\n",
       " 'அவரது',\n",
       " 'அவர்',\n",
       " 'அவர்கள்',\n",
       " 'அவள்',\n",
       " 'அவை',\n",
       " 'ஆகிய',\n",
       " 'ஆகியோர்',\n",
       " 'ஆகும்',\n",
       " 'இங்கு',\n",
       " 'இங்கே',\n",
       " 'இடத்தில்',\n",
       " 'இடம்',\n",
       " 'இதனால்',\n",
       " 'இதனை',\n",
       " 'இதன்',\n",
       " 'இதற்கு',\n",
       " 'இதில்',\n",
       " 'இது',\n",
       " 'இதை',\n",
       " 'இந்த',\n",
       " 'இந்தக்',\n",
       " 'இந்தத்',\n",
       " 'இந்தப்',\n",
       " 'இன்னும்',\n",
       " 'இப்போது',\n",
       " 'இரு',\n",
       " 'இருக்கும்',\n",
       " 'இருந்த',\n",
       " 'இருந்தது',\n",
       " 'இருந்து',\n",
       " 'இவர்',\n",
       " 'இவை',\n",
       " 'உன்',\n",
       " 'உள்ள',\n",
       " 'உள்ளது',\n",
       " 'உள்ளன',\n",
       " 'எந்த',\n",
       " 'என',\n",
       " 'எனக்',\n",
       " 'எனக்கு',\n",
       " 'எனப்படும்',\n",
       " 'எனவும்',\n",
       " 'எனவே',\n",
       " 'எனினும்',\n",
       " 'எனும்',\n",
       " 'என்',\n",
       " 'என்ன',\n",
       " 'என்னும்',\n",
       " 'என்பது',\n",
       " 'என்பதை',\n",
       " 'என்ற',\n",
       " 'என்று',\n",
       " 'என்றும்',\n",
       " 'எல்லாம்',\n",
       " 'ஏன்',\n",
       " 'ஒரு',\n",
       " 'ஒரே',\n",
       " 'ஓர்',\n",
       " 'கொண்ட',\n",
       " 'கொண்டு',\n",
       " 'கொள்ள',\n",
       " 'சற்று',\n",
       " 'சிறு',\n",
       " 'சில',\n",
       " 'சேர்ந்த',\n",
       " 'தனது',\n",
       " 'தன்',\n",
       " 'தவிர',\n",
       " 'தான்',\n",
       " 'நான்',\n",
       " 'நாம்',\n",
       " 'நீ',\n",
       " 'பற்றி',\n",
       " 'பற்றிய',\n",
       " 'பல',\n",
       " 'பலரும்',\n",
       " 'பல்வேறு',\n",
       " 'பின்',\n",
       " 'பின்னர்',\n",
       " 'பிற',\n",
       " 'பிறகு',\n",
       " 'பெரும்',\n",
       " 'பேர்',\n",
       " 'போது',\n",
       " 'போன்ற',\n",
       " 'போல',\n",
       " 'போல்',\n",
       " 'மட்டுமே',\n",
       " 'மட்டும்',\n",
       " 'மற்ற',\n",
       " 'மற்றும்',\n",
       " 'மிக',\n",
       " 'மிகவும்',\n",
       " 'மீது',\n",
       " 'முதல்',\n",
       " 'முறை',\n",
       " 'மேலும்',\n",
       " 'மேல்',\n",
       " 'யார்',\n",
       " 'வந்த',\n",
       " 'வந்து',\n",
       " 'வரும்',\n",
       " 'வரை',\n",
       " 'வரையில்',\n",
       " 'விட',\n",
       " 'விட்டு',\n",
       " 'வேண்டும்',\n",
       " 'வேறு']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"tamil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "feedcb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopwords.words(\"tamil\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "feaef259",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: 'C:\\\\Users\\\\shali\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords\\\\hindi'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mstopwords\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhindi\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\nltk\\corpus\\reader\\wordlist.py:21\u001b[39m, in \u001b[36mWordListCorpusReader.words\u001b[39m\u001b[34m(self, fileids, ignore_lines_startswith)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwords\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileids=\u001b[38;5;28;01mNone\u001b[39;00m, ignore_lines_startswith=\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m     20\u001b[39m         line\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m line_tokenize(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileids\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m line.startswith(ignore_lines_startswith)\n\u001b[32m     23\u001b[39m     ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\nltk\\corpus\\reader\\api.py:218\u001b[39m, in \u001b[36mCorpusReader.raw\u001b[39m\u001b[34m(self, fileids)\u001b[39m\n\u001b[32m    216\u001b[39m contents = []\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fileids:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    219\u001b[39m         contents.append(fp.read())\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m concat(contents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\nltk\\corpus\\reader\\api.py:231\u001b[39m, in \u001b[36mCorpusReader.open\u001b[39m\u001b[34m(self, file)\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[33;03mReturn an open stream that can be used to read the given file.\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03mIf the file's encoding is not None, then the stream will\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    228\u001b[39m \u001b[33;03m:param file: The file identifier of the file to read.\u001b[39;00m\n\u001b[32m    229\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    230\u001b[39m encoding = \u001b[38;5;28mself\u001b[39m.encoding(file)\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m stream = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_root\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m.open(encoding)\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\nltk\\data.py:333\u001b[39m, in \u001b[36mFileSystemPathPointer.join\u001b[39m\u001b[34m(self, fileid)\u001b[39m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjoin\u001b[39m(\u001b[38;5;28mself\u001b[39m, fileid):\n\u001b[32m    332\u001b[39m     _path = os.path.join(\u001b[38;5;28mself\u001b[39m._path, fileid)\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFileSystemPathPointer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\nltk\\data.py:311\u001b[39m, in \u001b[36mFileSystemPathPointer.__init__\u001b[39m\u001b[34m(self, _path)\u001b[39m\n\u001b[32m    309\u001b[39m _path = os.path.abspath(_path)\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(_path):\n\u001b[32m--> \u001b[39m\u001b[32m311\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo such file or directory: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % _path)\n\u001b[32m    312\u001b[39m \u001b[38;5;28mself\u001b[39m._path = _path\n",
      "\u001b[31mOSError\u001b[39m: No such file or directory: 'C:\\\\Users\\\\shali\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords\\\\hindi'"
     ]
    }
   ],
   "source": [
    "stopwords.words(\"hindi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c94c13b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['অতএব',\n",
       " 'অথচ',\n",
       " 'অথবা',\n",
       " 'অনুযায়ী',\n",
       " 'অনেক',\n",
       " 'অনেকে',\n",
       " 'অনেকেই',\n",
       " 'অন্তত',\n",
       " 'অন্য',\n",
       " 'অবধি',\n",
       " 'অবশ্য',\n",
       " 'অর্থাত',\n",
       " 'আই',\n",
       " 'আগামী',\n",
       " 'আগে',\n",
       " 'আগেই',\n",
       " 'আছে',\n",
       " 'আজ',\n",
       " 'আদ্যভাগে',\n",
       " 'আপনার',\n",
       " 'আপনি',\n",
       " 'আবার',\n",
       " 'আমরা',\n",
       " 'আমাকে',\n",
       " 'আমাদের',\n",
       " 'আমার',\n",
       " 'আমি',\n",
       " 'আর',\n",
       " 'আরও',\n",
       " 'ই',\n",
       " 'ইত্যাদি',\n",
       " 'ইহা',\n",
       " 'উচিত',\n",
       " 'উত্তর',\n",
       " 'উনি',\n",
       " 'উপর',\n",
       " 'উপরে',\n",
       " 'এ',\n",
       " 'এঁদের',\n",
       " 'এঁরা',\n",
       " 'এই',\n",
       " 'একই',\n",
       " 'একটি',\n",
       " 'একবার',\n",
       " 'একে',\n",
       " 'এক্',\n",
       " 'এখন',\n",
       " 'এখনও',\n",
       " 'এখানে',\n",
       " 'এখানেই',\n",
       " 'এটা',\n",
       " 'এটাই',\n",
       " 'এটি',\n",
       " 'এত',\n",
       " 'এতটাই',\n",
       " 'এতে',\n",
       " 'এদের',\n",
       " 'এব',\n",
       " 'এবং',\n",
       " 'এবার',\n",
       " 'এমন',\n",
       " 'এমনকী',\n",
       " 'এমনি',\n",
       " 'এর',\n",
       " 'এরা',\n",
       " 'এল',\n",
       " 'এস',\n",
       " 'এসে',\n",
       " 'ঐ',\n",
       " 'ও',\n",
       " 'ওঁদের',\n",
       " 'ওঁর',\n",
       " 'ওঁরা',\n",
       " 'ওই',\n",
       " 'ওকে',\n",
       " 'ওখানে',\n",
       " 'ওদের',\n",
       " 'ওর',\n",
       " 'ওরা',\n",
       " 'কখনও',\n",
       " 'কত',\n",
       " 'কবে',\n",
       " 'কমনে',\n",
       " 'কয়েক',\n",
       " 'কয়েকটি',\n",
       " 'করছে',\n",
       " 'করছেন',\n",
       " 'করতে',\n",
       " 'করবে',\n",
       " 'করবেন',\n",
       " 'করলে',\n",
       " 'করলেন',\n",
       " 'করা',\n",
       " 'করাই',\n",
       " 'করায়',\n",
       " 'করার',\n",
       " 'করি',\n",
       " 'করিতে',\n",
       " 'করিয়া',\n",
       " 'করিয়ে',\n",
       " 'করে',\n",
       " 'করেই',\n",
       " 'করেছিলেন',\n",
       " 'করেছে',\n",
       " 'করেছেন',\n",
       " 'করেন',\n",
       " 'কাউকে',\n",
       " 'কাছ',\n",
       " 'কাছে',\n",
       " 'কাজ',\n",
       " 'কাজে',\n",
       " 'কারও',\n",
       " 'কারণ',\n",
       " 'কি',\n",
       " 'কিংবা',\n",
       " 'কিছু',\n",
       " 'কিছুই',\n",
       " 'কিন্তু',\n",
       " 'কী',\n",
       " 'কে',\n",
       " 'কেউ',\n",
       " 'কেউই',\n",
       " 'কেখা',\n",
       " 'কেন',\n",
       " 'কোটি',\n",
       " 'কোন',\n",
       " 'কোনও',\n",
       " 'কোনো',\n",
       " 'ক্ষেত্রে',\n",
       " 'কয়েক',\n",
       " 'খুব',\n",
       " 'গিয়ে',\n",
       " 'গিয়েছে',\n",
       " 'গিয়ে',\n",
       " 'গুলি',\n",
       " 'গেছে',\n",
       " 'গেল',\n",
       " 'গেলে',\n",
       " 'গোটা',\n",
       " 'চলে',\n",
       " 'চান',\n",
       " 'চায়',\n",
       " 'চার',\n",
       " 'চালু',\n",
       " 'চেয়ে',\n",
       " 'চেষ্টা',\n",
       " 'ছাড়া',\n",
       " 'ছাড়াও',\n",
       " 'ছিল',\n",
       " 'ছিলেন',\n",
       " 'জন',\n",
       " 'জনকে',\n",
       " 'জনের',\n",
       " 'জন্য',\n",
       " 'জন্যওজে',\n",
       " 'জানতে',\n",
       " 'জানা',\n",
       " 'জানানো',\n",
       " 'জানায়',\n",
       " 'জানিয়ে',\n",
       " 'জানিয়েছে',\n",
       " 'জে',\n",
       " 'জ্নজন',\n",
       " 'টি',\n",
       " 'ঠিক',\n",
       " 'তখন',\n",
       " 'তত',\n",
       " 'তথা',\n",
       " 'তবু',\n",
       " 'তবে',\n",
       " 'তা',\n",
       " 'তাঁকে',\n",
       " 'তাঁদের',\n",
       " 'তাঁর',\n",
       " 'তাঁরা',\n",
       " 'তাঁাহারা',\n",
       " 'তাই',\n",
       " 'তাও',\n",
       " 'তাকে',\n",
       " 'তাতে',\n",
       " 'তাদের',\n",
       " 'তার',\n",
       " 'তারপর',\n",
       " 'তারা',\n",
       " 'তারৈ',\n",
       " 'তাহলে',\n",
       " 'তাহা',\n",
       " 'তাহাতে',\n",
       " 'তাহার',\n",
       " 'তিনঐ',\n",
       " 'তিনি',\n",
       " 'তিনিও',\n",
       " 'তুমি',\n",
       " 'তুলে',\n",
       " 'তেমন',\n",
       " 'তো',\n",
       " 'তোমার',\n",
       " 'থাকবে',\n",
       " 'থাকবেন',\n",
       " 'থাকা',\n",
       " 'থাকায়',\n",
       " 'থাকে',\n",
       " 'থাকেন',\n",
       " 'থেকে',\n",
       " 'থেকেই',\n",
       " 'থেকেও',\n",
       " 'দিকে',\n",
       " 'দিতে',\n",
       " 'দিন',\n",
       " 'দিয়ে',\n",
       " 'দিয়েছে',\n",
       " 'দিয়েছেন',\n",
       " 'দিলেন',\n",
       " 'দু',\n",
       " 'দুই',\n",
       " 'দুটি',\n",
       " 'দুটো',\n",
       " 'দেওয়া',\n",
       " 'দেওয়ার',\n",
       " 'দেওয়া',\n",
       " 'দেখতে',\n",
       " 'দেখা',\n",
       " 'দেখে',\n",
       " 'দেন',\n",
       " 'দেয়',\n",
       " 'দ্বারা',\n",
       " 'ধরা',\n",
       " 'ধরে',\n",
       " 'ধামার',\n",
       " 'নতুন',\n",
       " 'নয়',\n",
       " 'না',\n",
       " 'নাই',\n",
       " 'নাকি',\n",
       " 'নাগাদ',\n",
       " 'নানা',\n",
       " 'নিজে',\n",
       " 'নিজেই',\n",
       " 'নিজেদের',\n",
       " 'নিজের',\n",
       " 'নিতে',\n",
       " 'নিয়ে',\n",
       " 'নিয়ে',\n",
       " 'নেই',\n",
       " 'নেওয়া',\n",
       " 'নেওয়ার',\n",
       " 'নেওয়া',\n",
       " 'নয়',\n",
       " 'পক্ষে',\n",
       " 'পর',\n",
       " 'পরে',\n",
       " 'পরেই',\n",
       " 'পরেও',\n",
       " 'পর্যন্ত',\n",
       " 'পাওয়া',\n",
       " 'পাচ',\n",
       " 'পারি',\n",
       " 'পারে',\n",
       " 'পারেন',\n",
       " 'পি',\n",
       " 'পেয়ে',\n",
       " 'পেয়্র্',\n",
       " 'প্রতি',\n",
       " 'প্রথম',\n",
       " 'প্রভৃতি',\n",
       " 'প্রযন্ত',\n",
       " 'প্রাথমিক',\n",
       " 'প্রায়',\n",
       " 'প্রায়',\n",
       " 'ফলে',\n",
       " 'ফিরে',\n",
       " 'ফের',\n",
       " 'বক্তব্য',\n",
       " 'বদলে',\n",
       " 'বন',\n",
       " 'বরং',\n",
       " 'বলতে',\n",
       " 'বলল',\n",
       " 'বললেন',\n",
       " 'বলা',\n",
       " 'বলে',\n",
       " 'বলেছেন',\n",
       " 'বলেন',\n",
       " 'বসে',\n",
       " 'বহু',\n",
       " 'বা',\n",
       " 'বাদে',\n",
       " 'বার',\n",
       " 'বি',\n",
       " 'বিনা',\n",
       " 'বিভিন্ন',\n",
       " 'বিশেষ',\n",
       " 'বিষয়টি',\n",
       " 'বেশ',\n",
       " 'বেশি',\n",
       " 'ব্যবহার',\n",
       " 'ব্যাপারে',\n",
       " 'ভাবে',\n",
       " 'ভাবেই',\n",
       " 'মতো',\n",
       " 'মতোই',\n",
       " 'মধ্যভাগে',\n",
       " 'মধ্যে',\n",
       " 'মধ্যেই',\n",
       " 'মধ্যেও',\n",
       " 'মনে',\n",
       " 'মাত্র',\n",
       " 'মাধ্যমে',\n",
       " 'মোট',\n",
       " 'মোটেই',\n",
       " 'যখন',\n",
       " 'যত',\n",
       " 'যতটা',\n",
       " 'যথেষ্ট',\n",
       " 'যদি',\n",
       " 'যদিও',\n",
       " 'যা',\n",
       " 'যাঁর',\n",
       " 'যাঁরা',\n",
       " 'যাওয়া',\n",
       " 'যাওয়ার',\n",
       " 'যাওয়া',\n",
       " 'যাকে',\n",
       " 'যাচ্ছে',\n",
       " 'যাতে',\n",
       " 'যাদের',\n",
       " 'যান',\n",
       " 'যাবে',\n",
       " 'যায়',\n",
       " 'যার',\n",
       " 'যারা',\n",
       " 'যিনি',\n",
       " 'যে',\n",
       " 'যেখানে',\n",
       " 'যেতে',\n",
       " 'যেন',\n",
       " 'যেমন',\n",
       " 'র',\n",
       " 'রকম',\n",
       " 'রয়েছে',\n",
       " 'রাখা',\n",
       " 'রেখে',\n",
       " 'লক্ষ',\n",
       " 'শুধু',\n",
       " 'শুরু',\n",
       " 'সঙ্গে',\n",
       " 'সঙ্গেও',\n",
       " 'সব',\n",
       " 'সবার',\n",
       " 'সমস্ত',\n",
       " 'সম্প্রতি',\n",
       " 'সহ',\n",
       " 'সহিত',\n",
       " 'সাধারণ',\n",
       " 'সামনে',\n",
       " 'সি',\n",
       " 'সুতরাং',\n",
       " 'সে',\n",
       " 'সেই',\n",
       " 'সেখান',\n",
       " 'সেখানে',\n",
       " 'সেটা',\n",
       " 'সেটাই',\n",
       " 'সেটাও',\n",
       " 'সেটি',\n",
       " 'স্পষ্ট',\n",
       " 'স্বয়ং',\n",
       " 'হইতে',\n",
       " 'হইবে',\n",
       " 'হইয়া',\n",
       " 'হওয়া',\n",
       " 'হওয়ায়',\n",
       " 'হওয়ার',\n",
       " 'হচ্ছে',\n",
       " 'হত',\n",
       " 'হতে',\n",
       " 'হতেই',\n",
       " 'হন',\n",
       " 'হবে',\n",
       " 'হবেন',\n",
       " 'হয়',\n",
       " 'হয়তো',\n",
       " 'হয়নি',\n",
       " 'হয়ে',\n",
       " 'হয়েই',\n",
       " 'হয়েছিল',\n",
       " 'হয়েছে',\n",
       " 'হয়েছেন',\n",
       " 'হল',\n",
       " 'হলে',\n",
       " 'হলেই',\n",
       " 'হলেও',\n",
       " 'হলো',\n",
       " 'হাজার',\n",
       " 'হিসাবে',\n",
       " 'হৈলে',\n",
       " 'হোক',\n",
       " 'হয়']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words(\"bengali\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc829f5f",
   "metadata": {},
   "source": [
    "# POS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0c51cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fca44c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sam', 'is', 'a', 'natural', 'when', 'it', 'comes', 'to', 'drawing']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = \"sam is a natural when it comes to drawing\"\n",
    "sent_tokens = word_tokenize(sent)\n",
    "sent_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7db7097d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sam', 'NN')]\n",
      "[('is', 'VBZ')]\n",
      "[('a', 'DT')]\n",
      "[('natural', 'JJ')]\n",
      "[('when', 'WRB')]\n",
      "[('it', 'PRP')]\n",
      "[('comes', 'VBZ')]\n",
      "[('to', 'TO')]\n",
      "[('drawing', 'VBG')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9d5563a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Artificial', 'JJ')]\n",
      "[('Intelligence', 'NN')]\n",
      "[('refers', 'NNS')]\n",
      "[('to', 'TO')]\n",
      "[('the', 'DT')]\n",
      "[('intelligence', 'NN')]\n",
      "[('of', 'IN')]\n",
      "[('machines', 'NNS')]\n",
      "[('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "sentence = \"Artificial Intelligence refers to the intelligence of machines.\"\n",
    "sent_tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "for token in sent_tokens:\n",
    "    print(nltk.pos_tag([token]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1863b33a",
   "metadata": {},
   "source": [
    "# NER ( NAMED ENTITY RECOGNITION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0bbe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ne_chunk\n",
    "NE_sent = \"The US president stays in the WhiteHouse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a3ccc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'US', 'president', 'stays', 'in', 'the', 'WhiteHouse']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NE_tokens = word_tokenize(NE_sent)\n",
    "NE_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "595200d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('US', 'NNP'),\n",
       " ('president', 'NN'),\n",
       " ('stays', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('WhiteHouse', 'NNP')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NE_tags = nltk.pos_tag(NE_tokens)\n",
    "NE_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "092bd9a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  (GSP US/NNP)\n",
      "  president/NN\n",
      "  stays/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  (ORGANIZATION WhiteHouse/NNP))\n"
     ]
    }
   ],
   "source": [
    "NE_NER = ne_chunk(NE_tags)\n",
    "print(NE_NER)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
